{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/roksana/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from itertools import chain\n",
    "from nltk.corpus import wordnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_synonyms(word):\n",
    "    synonyms = wordnet.synsets(word)\n",
    "    lemmas = set(chain.from_iterable([word.lemma_names() for word in synonyms]))\n",
    "    # only keep synonyms with the same pos tag\n",
    "    lemmas = set([lemma for lemma in lemmas if wordnet.synsets(lemma) and wordnet.synsets(lemma)[0].pos() == wordnet.synsets(word)[0].pos()])\n",
    "    # remove the original word\n",
    "    lemmas.discard(word)\n",
    "    return lemmas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "353692\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "path = '/Users/roksana/Projects/definitions-1/semeval2020_ulscd_eng/corpus2/lemma/ccoha2.txt/ccoha2.txt'\n",
    "\n",
    "with open(path, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# if there are _ in the lines, remove them and the following pos tag\n",
    "def remove_pos_tags(sentence):\n",
    "    return re.sub(r'(\\b\\w+?)_\\w+\\b', r'\\1', sentence)\n",
    "lines = [remove_pos_tags(line) for line in lines]\n",
    "\n",
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /Users/roksana/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     /Users/roksana/nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of 100 somewhat common words with varied verbs, nouns, and adjectives:\n",
      "\n",
      "political\n",
      "regard\n",
      "aspects\n",
      "thick\n",
      "sweet\n",
      "sun\n",
      "hot\n",
      "coming\n",
      "obtained\n",
      "london\n",
      "medical\n",
      "sharp\n",
      "conventional\n",
      "forest\n",
      "device\n",
      "formed\n",
      "expected\n",
      "late\n",
      "official\n",
      "stood\n",
      "becoming\n",
      "forth\n",
      "issues\n",
      "broken\n",
      "understanding\n",
      "health\n",
      "paper\n",
      "asking\n",
      "being\n",
      "young\n",
      "party\n",
      "technique\n",
      "neighborhood\n",
      "russian\n",
      "wage\n",
      "la\n",
      "completed\n",
      "unique\n",
      "united\n",
      "central\n",
      "affairs\n",
      "writer\n",
      "sitting\n",
      "unable\n",
      "catholic\n",
      "train\n",
      "methods\n",
      "move\n",
      "joseph\n",
      "suggest\n",
      "military\n",
      "single\n",
      "planned\n",
      "reasonable\n",
      "seem\n",
      "project\n",
      "america\n",
      "group\n",
      "club\n",
      "career\n",
      "given\n",
      "du\n",
      "improved\n",
      "horses\n",
      "compared\n",
      "answered\n",
      "truth\n",
      "open\n",
      "added\n",
      "child\n",
      "friday\n",
      "communication\n",
      "literary\n",
      "organized\n",
      "waiting\n",
      "company\n",
      "rule\n",
      "considered\n",
      "personal\n",
      "present\n",
      "fundamental\n",
      "authority\n",
      "mean\n",
      "believe\n",
      "concerning\n",
      "developed\n",
      "declared\n",
      "discussion\n",
      "miss\n",
      "victory\n",
      "grew\n",
      "represented\n",
      "instance\n",
      "march\n",
      "pain\n",
      "high\n",
      "financial\n",
      "hundred\n",
      "contact\n",
      "prove\n",
      "heat\n",
      "christ\n",
      "independent\n",
      "analysis\n",
      "warm\n",
      "appropriate\n",
      "article\n",
      "produced\n",
      "wonderful\n",
      "love\n",
      "fourth\n",
      "works\n",
      "directed\n",
      "faculty\n",
      "assume\n",
      "stream\n",
      "said\n",
      "grounds\n",
      "man\n",
      "flesh\n",
      "established\n",
      "approval\n",
      "feet\n",
      "responsibility\n",
      "english\n",
      "lady\n",
      "charged\n",
      "forces\n",
      "down\n",
      "practices\n",
      "middle\n",
      "federal\n",
      "include\n",
      "research\n",
      "included\n",
      "david\n",
      "knowing\n",
      "success\n",
      "little\n",
      "moral\n",
      "conditions\n",
      "dogs\n",
      "costs\n",
      "signal\n",
      "headquarters\n",
      "complex\n",
      "beginning\n",
      "knife\n",
      "role\n",
      "opportunity\n",
      "night\n",
      "activity\n",
      "led\n",
      "particular\n",
      "review\n",
      "allow\n",
      "asked\n",
      "covered\n",
      "runs\n",
      "wagon\n",
      "trial\n",
      "broke\n",
      "sleep\n",
      "southern\n",
      "extended\n",
      "towards\n",
      "orchestra\n",
      "following\n",
      "commercial\n",
      "contract\n",
      "british\n",
      "mark\n",
      "add\n",
      "figures\n",
      "bottom\n",
      "modern\n",
      "content\n",
      "india\n",
      "friend\n",
      "sounds\n",
      "gave\n",
      "let\n",
      "practice\n",
      "proved\n",
      "using\n",
      "determine\n",
      "basis\n",
      "second\n",
      "sir\n",
      "resolution\n",
      "sat\n",
      "text\n",
      "place\n",
      "foreign\n",
      "tried\n",
      "east\n",
      "assigned\n",
      "agree\n",
      "produce\n",
      "pair\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from nltk import FreqDist, pos_tag\n",
    "import random\n",
    "\n",
    "# Download necessary NLTK data files\n",
    "nltk.download('brown')\n",
    "nltk.download('universal_tagset')\n",
    "\n",
    "# Step 1: Extract words from the Brown Corpus\n",
    "words = [word.lower() for word in brown.words() if word.isalpha()]\n",
    "\n",
    "# Step 2: Calculate word frequencies\n",
    "freq_dist = FreqDist(words)\n",
    "\n",
    "# Step 3: Set frequency thresholds\n",
    "MIN_FREQ = 50     # Minimum frequency threshold\n",
    "MAX_FREQ = 2000   # Maximum frequency threshold\n",
    "\n",
    "# Step 4: Filter words by frequency\n",
    "filtered_words = [word for word in set(words)\n",
    "                  if MIN_FREQ <= freq_dist[word] <= MAX_FREQ]\n",
    "\n",
    "# Step 5: Perform POS tagging\n",
    "tagged_words = pos_tag(filtered_words, tagset='universal')\n",
    "\n",
    "# Step 6: Filter words by desired POS (nouns, verbs, adjectives)\n",
    "desired_tags = {'NOUN', 'VERB', 'ADJ'}\n",
    "filtered_tagged_words = [(word, tag) for word, tag in tagged_words if tag in desired_tags]\n",
    "\n",
    "# Step 7: Separate words by POS\n",
    "nouns = [word for word, tag in filtered_tagged_words if tag == 'NOUN']\n",
    "verbs = [word for word, tag in filtered_tagged_words if tag == 'VERB']\n",
    "adjectives = [word for word, tag in filtered_tagged_words if tag == 'ADJ']\n",
    "\n",
    "# Step 8: Decide the number of words from each POS\n",
    "num_words = 200\n",
    "num_per_pos = num_words // 3\n",
    "\n",
    "# Step 9: Randomly select words from each POS category\n",
    "random.seed(42)  # For reproducibility\n",
    "selected_nouns = random.sample(nouns, min(len(nouns), num_per_pos))\n",
    "selected_verbs = random.sample(verbs, min(len(verbs), num_per_pos))\n",
    "selected_adjectives = random.sample(adjectives, min(len(adjectives), num_per_pos))\n",
    "\n",
    "# Step 10: Combine and shuffle the final list\n",
    "final_words = selected_nouns + selected_verbs + selected_adjectives\n",
    "random.shuffle(final_words)\n",
    "\n",
    "# Step 11: Fill in if fewer than 100 words\n",
    "if len(final_words) < num_words:\n",
    "    additional_words_needed = num_words - len(final_words)\n",
    "    remaining_words = [word for word in filtered_words if word not in final_words]\n",
    "    random.shuffle(remaining_words)\n",
    "    final_words.extend(remaining_words[:additional_words_needed])\n",
    "\n",
    "# Step 12: Output the list of words\n",
    "print(\"List of 100 somewhat common words with varied verbs, nouns, and adjectives:\\n\")\n",
    "for word in final_words[:200]:\n",
    "    print(word)\n",
    "print(len(final_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'political': set()\n",
      "'hot': set()\n",
      "'conventional': {'ceremonious'}\n",
      "'late': set()\n",
      "'official': {'functionary'}\n",
      "'health': {'wellness'}\n",
      "'technique': {'proficiency'}\n",
      "'russian': {'Russian'}\n",
      "'writer': {'author'}\n",
      "'catholic': {'Catholic'}\n",
      "'seem': {'appear'}\n",
      "'du': set()\n",
      "'communication': {'communicating'}\n",
      "'literary': set()\n",
      "'personal': set()\n",
      "'victory': {'triumph'}\n",
      "'financial': {'fiscal'}\n",
      "'warm': {'warm_up'}\n",
      "'article': {'clause'}\n",
      "'moral': {'lesson'}\n",
      "'opportunity': {'chance'}\n",
      "'southern': set()\n",
      "'towards': set()\n",
      "'orchestra': set()\n",
      "'commercial': {'commercial_message'}\n",
      "'sir': {'Sir'}\n",
      "'foreign': {'strange'}\n",
      "136 136 136\n"
     ]
    }
   ],
   "source": [
    "# for each word, select 200 sentences that contain it\n",
    "word_sentences = {word: [] for word in final_words}\n",
    "for line in lines:\n",
    "    for word in final_words:\n",
    "        if word in line:\n",
    "            word_sentences[word].append(line)\n",
    "\n",
    "# remove words that have less than 30 sentences and limit the number of sentences to 100\n",
    "for word in list(word_sentences.keys()):\n",
    "    sentences = word_sentences[word]\n",
    "    if len(sentences) < 30:\n",
    "        word_sentences.pop(word)\n",
    "        final_words.remove(word)\n",
    "    else:\n",
    "        word_sentences[word] = sentences[:100]\n",
    "\n",
    "\n",
    "word_synonyms = {word: set() for word in final_words}\n",
    "for word in final_words:\n",
    "    word_synonyms[word] = get_synonyms(word)\n",
    "\n",
    "\n",
    "synonym_counts = [len(synonyms) for synonyms in word_synonyms.values()]\n",
    "# Remove words with less than 2 synonyms\n",
    "for word in list(word_synonyms.keys()):\n",
    "    synonyms = word_synonyms[word]\n",
    "    if len(synonyms) < 2:\n",
    "        print(f\"'{word}': {synonyms}\")\n",
    "        word_synonyms.pop(word)\n",
    "        word_sentences.pop(word, None)\n",
    "        final_words.remove(word)\n",
    "\n",
    "print(len(word_synonyms), len(word_sentences), len(final_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regard: 100\n",
      "thick: 100\n",
      "sweet: 100\n",
      "sun: 100\n",
      "coming: 100\n",
      "london: 100\n",
      "medical: 100\n",
      "sharp: 100\n",
      "forest: 100\n",
      "device: 100\n",
      "formed: 100\n",
      "expected: 100\n",
      "forth: 100\n",
      "broken: 100\n",
      "understanding: 100\n",
      "paper: 100\n",
      "being: 100\n",
      "young: 100\n",
      "party: 100\n",
      "neighborhood: 100\n",
      "wage: 100\n",
      "la: 100\n",
      "unique: 100\n",
      "united: 100\n",
      "central: 100\n",
      "unable: 100\n",
      "train: 100\n",
      "move: 100\n",
      "joseph: 100\n",
      "suggest: 100\n",
      "military: 100\n",
      "single: 100\n",
      "planned: 72\n",
      "reasonable: 100\n",
      "project: 100\n",
      "america: 100\n",
      "group: 100\n",
      "club: 100\n",
      "career: 100\n",
      "given: 60\n",
      "horses: 31\n",
      "truth: 100\n",
      "open: 100\n",
      "added: 43\n",
      "child: 100\n",
      "friday: 100\n",
      "company: 100\n",
      "rule: 100\n",
      "present: 100\n",
      "fundamental: 100\n",
      "authority: 100\n",
      "mean: 100\n",
      "believe: 100\n",
      "concerning: 100\n",
      "developed: 48\n",
      "discussion: 100\n",
      "miss: 100\n",
      "instance: 100\n",
      "march: 100\n",
      "pain: 100\n",
      "high: 100\n",
      "hundred: 100\n",
      "contact: 100\n",
      "prove: 100\n",
      "heat: 100\n",
      "christ: 100\n",
      "independent: 100\n",
      "analysis: 100\n",
      "appropriate: 100\n",
      "wonderful: 100\n",
      "love: 100\n",
      "fourth: 100\n",
      "works: 100\n",
      "faculty: 100\n",
      "assume: 100\n",
      "stream: 100\n",
      "said: 46\n",
      "man: 100\n",
      "flesh: 100\n",
      "approval: 100\n",
      "feet: 33\n",
      "responsibility: 100\n",
      "english: 100\n",
      "lady: 100\n",
      "down: 100\n",
      "middle: 100\n",
      "federal: 100\n",
      "include: 100\n",
      "research: 100\n",
      "david: 100\n",
      "knowing: 30\n",
      "success: 100\n",
      "little: 100\n",
      "signal: 100\n",
      "headquarters: 100\n",
      "complex: 100\n",
      "beginning: 100\n",
      "knife: 100\n",
      "role: 100\n",
      "night: 100\n",
      "activity: 100\n",
      "led: 100\n",
      "particular: 100\n",
      "review: 100\n",
      "allow: 100\n",
      "asked: 36\n",
      "covered: 78\n",
      "runs: 35\n",
      "wagon: 100\n",
      "trial: 100\n",
      "broke: 100\n",
      "sleep: 100\n",
      "following: 100\n",
      "contract: 100\n",
      "british: 100\n",
      "mark: 100\n",
      "add: 100\n",
      "bottom: 100\n",
      "modern: 100\n",
      "content: 100\n",
      "india: 100\n",
      "friend: 100\n",
      "let: 100\n",
      "practice: 100\n",
      "using: 100\n",
      "determine: 100\n",
      "basis: 100\n",
      "second: 100\n",
      "resolution: 100\n",
      "sat: 100\n",
      "text: 100\n",
      "place: 100\n",
      "east: 100\n",
      "agree: 100\n",
      "produce: 100\n",
      "pair: 100\n"
     ]
    }
   ],
   "source": [
    "# print the len of sentences for each word in word_sentences\n",
    "for word, sentences in word_sentences.items():\n",
    "    print(f\"{word}: {len(sentences)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each word, select up to 5 synonyms that aren't the word itself\n",
    "# word_synonyms = {word: random.sample(synonyms, min(5, len(synonyms))) for word, synonyms in word_synonyms.items()}\n",
    "\n",
    "# for each synonym, select up to 100 sentences that contain it\n",
    "word_synonym_sentences = {}\n",
    "for word in word_synonyms.keys():\n",
    "    word_synonym_sentences[word] = {}\n",
    "    for synonym in word_synonyms[word]:\n",
    "        word_synonym_sentences[word][synonym] = []\n",
    "        for line in lines:\n",
    "            if synonym in line:\n",
    "                word_synonym_sentences[word][synonym].append(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed sense paying_attention from word regard\n",
      "Removed sense attentiveness from word regard\n",
      "Removed sense compliments from word regard\n",
      "Removed sense Henry_Sweet from word sweet\n",
      "Removed sense sugariness from word sweet\n",
      "Removed sense afters from word sweet\n",
      "Removed sense Sweet from word sweet\n",
      "Removed sense confection from word sweet\n",
      "Removed sense Dominicus from word sun\n",
      "Removed sense Sun from word sun\n",
      "Removed sense Lord's_Day from word sun\n",
      "Removed sense Sunday from word sun\n",
      "Removed sense approaching from word coming\n",
      "Removed sense sexual_climax from word coming\n",
      "Removed sense capital_of_the_United_Kingdom from word london\n",
      "Removed sense Jack_London from word london\n",
      "Removed sense Greater_London from word london\n",
      "Removed sense John_Griffith_Chaney from word london\n",
      "Removed sense British_capital from word london\n",
      "Removed sense London from word london\n",
      "Removed sense medical_checkup from word medical\n",
      "Removed sense checkup from word medical\n",
      "Removed sense medical_exam from word medical\n",
      "Removed sense health_check from word medical\n",
      "Removed sense medical_examination from word medical\n",
      "Removed sense woodland from word forest\n",
      "Removed sense timberland from word forest\n",
      "Removed sense gimmick from word device\n",
      "Removed sense organise from word formed\n",
      "Removed sense take_form from word formed\n",
      "Removed sense take_shape from word formed\n",
      "Removed sense have_a_bun_in_the_oven from word expected\n",
      "Removed sense gestate from word expected\n",
      "Removed sense Forth from word forth\n",
      "Removed sense Forth_River from word forth\n",
      "Removed sense go_against from word broken\n",
      "Removed sense transgress from word broken\n",
      "Removed sense snap_off from word broken\n",
      "Removed sense fall_apart from word broken\n",
      "Removed sense break_down from word broken\n",
      "Removed sense kick_downstairs from word broken\n",
      "Removed sense break_out from word broken\n",
      "Removed sense divulge from word broken\n",
      "Removed sense come_apart from word broken\n",
      "Removed sense give_way from word broken\n",
      "Removed sense bring_out from word broken\n",
      "Removed sense break_up from word broken\n",
      "Removed sense break_in from word broken\n",
      "Removed sense unwrap from word broken\n",
      "Removed sense discontinue from word broken\n",
      "Removed sense humbled from word broken\n",
      "Removed sense get_around from word broken\n",
      "Removed sense confused from word broken\n",
      "Removed sense give_out from word broken\n",
      "Removed sense crushed from word broken\n",
      "Removed sense break-dance from word broken\n",
      "Removed sense break_away from word broken\n",
      "Removed sense recrudesce from word broken\n",
      "Removed sense break_off from word broken\n",
      "Removed sense give_away from word broken\n",
      "Removed sense demote from word broken\n",
      "Removed sense infract from word broken\n",
      "Removed sense conk_out from word broken\n",
      "Removed sense let_on from word broken\n",
      "Removed sense busted from word broken\n",
      "Removed sense go_bad from word broken\n",
      "Removed sense disordered from word broken\n",
      "Removed sense humiliated from word broken\n",
      "Removed sense let_out from word broken\n",
      "Removed sense wear_out from word broken\n",
      "Removed sense relegate from word broken\n",
      "Removed sense get_out from word broken\n",
      "Removed sense fall_in from word broken\n",
      "Removed sense discernment from word understanding\n",
      "Removed sense wallpaper from word paper\n",
      "Removed sense newspaper_publisher from word paper\n",
      "Removed sense beingness from word being\n",
      "Removed sense Pres_Young from word young\n",
      "Removed sense Lester_Willis_Young from word young\n",
      "Removed sense Whitney_Young from word young\n",
      "Removed sense Edward_Young from word young\n",
      "Removed sense Danton_True_Young from word young\n",
      "Removed sense Cy_Young from word young\n",
      "Removed sense Thomas_Young from word young\n",
      "Removed sense Loretta_Young from word young\n",
      "Removed sense Brigham_Young from word young\n",
      "Removed sense Whitney_Moore_Young_Jr. from word young\n",
      "Removed sense Young from word young\n",
      "Removed sense political_party from word party\n",
      "Removed sense neck_of_the_woods from word neighborhood\n",
      "Removed sense neighbourhood from word neighborhood\n",
      "Removed sense remuneration from word wage\n",
      "Removed sense lanthanum from word la\n",
      "Removed sense LA from word la\n",
      "Removed sense Louisiana from word la\n",
      "Removed sense Pelican_State from word la\n",
      "Removed sense atomic_number_57 from word la\n",
      "Removed sense La from word la\n",
      "Removed sense unequalled from word unique\n",
      "Removed sense unequaled from word unique\n",
      "Removed sense unparalleled from word unique\n",
      "Removed sense link_up from word united\n",
      "Removed sense joined from word united\n",
      "Removed sense telephone_exchange from word central\n",
      "Removed sense ineffectual from word unable\n",
      "Removed sense wagon_train from word train\n",
      "Removed sense power_train from word train\n",
      "Removed sense gearing from word train\n",
      "Removed sense railroad_train from word train\n",
      "Removed sense geartrain from word train\n",
      "Removed sense motility from word move\n",
      "Removed sense relocation from word move\n",
      "Removed sense Chief_Joseph from word joseph\n",
      "Removed sense Joseph from word joseph\n",
      "Removed sense paint_a_picture from word suggest\n",
      "Removed sense war_machine from word military\n",
      "Removed sense military_machine from word military\n",
      "Removed sense armed_forces from word military\n",
      "Removed sense armed_services from word military\n",
      "Removed sense I from word single\n",
      "Removed sense bingle from word single\n",
      "Removed sense be_after from word planned\n",
      "Removed sense plotted from word planned\n",
      "Removed sense undertaking from word project\n",
      "Removed sense U.S. from word america\n",
      "Removed sense the_States from word america\n",
      "Removed sense United_States from word america\n",
      "Removed sense US from word america\n",
      "Removed sense USA from word america\n",
      "Removed sense U.S.A. from word america\n",
      "Removed sense America from word america\n",
      "Removed sense United_States_of_America from word america\n",
      "Removed sense mathematical_group from word group\n",
      "Removed sense chemical_group from word group\n",
      "Removed sense baseball_club from word club\n",
      "Removed sense nightspot from word club\n",
      "Removed sense bludgeon from word club\n",
      "Removed sense ball_club from word club\n",
      "Removed sense golf_club from word club\n",
      "Removed sense golf-club from word club\n",
      "Removed sense night_club from word club\n",
      "Removed sense cabaret from word club\n",
      "Removed sense social_club from word club\n",
      "Removed sense life_history from word career\n",
      "Removed sense calling from word career\n",
      "Removed sense presumption from word given\n",
      "Removed sense cave_in from word given\n",
      "Removed sense precondition from word given\n",
      "Removed sense tending from word given\n",
      "Removed sense sawhorse from word horses\n",
      "Removed sense Equus_caballus from word horses\n",
      "Removed sense horse_cavalry from word horses\n",
      "Removed sense sawbuck from word horses\n",
      "Removed sense gymnastic_horse from word horses\n",
      "Removed sense Truth from word truth\n",
      "Removed sense verity from word truth\n",
      "Removed sense trueness from word truth\n",
      "Removed sense Sojourner_Truth from word truth\n",
      "Removed sense the_true from word truth\n",
      "Removed sense true_statement from word truth\n",
      "Removed sense open_air from word open\n",
      "Removed sense heart-to-heart from word open\n",
      "Removed sense out-of-doors from word open\n",
      "Removed sense summate from word added\n",
      "Removed sense sum_up from word added\n",
      "Removed sense add_up from word added\n",
      "Removed sense tote_up from word added\n",
      "Removed sense add_together from word added\n",
      "Removed sense tot_up from word added\n",
      "Removed sense tyke from word child\n",
      "Removed sense tiddler from word child\n",
      "Removed sense shaver from word child\n",
      "Removed sense nestling from word child\n",
      "Removed sense nipper from word child\n",
      "Removed sense small_fry from word child\n",
      "Removed sense tike from word child\n",
      "Removed sense Fri from word friday\n",
      "Removed sense Friday from word friday\n",
      "Removed sense ship's_company from word company\n",
      "Removed sense dominion from word rule\n",
      "Removed sense linguistic_rule from word rule\n",
      "Removed sense present_tense from word present\n",
      "Removed sense fundamental_frequency from word fundamental\n",
      "Removed sense first_harmonic from word fundamental\n",
      "Removed sense potency from word authority\n",
      "Removed sense say-so from word authority\n",
      "Removed sense self-assurance from word authority\n",
      "Removed sense self-confidence from word authority\n",
      "Removed sense sureness from word authority\n",
      "Removed sense authorization from word authority\n",
      "Removed sense government_agency from word authority\n",
      "Removed sense authorisation from word authority\n",
      "Removed sense federal_agency from word authority\n",
      "Removed sense mean_value from word mean\n",
      "Removed sense bear_on from word concerning\n",
      "Removed sense come_to from word concerning\n",
      "Removed sense have-to_doe_with from word concerning\n",
      "Removed sense touch_on from word concerning\n",
      "Removed sense explicate from word developed\n",
      "Removed sense uprise from word developed\n",
      "Removed sense make_grow from word developed\n",
      "Removed sense recrudesce from word developed\n",
      "Removed sense build_up from word developed\n",
      "Removed sense modernise from word developed\n",
      "Removed sense spring_up from word developed\n",
      "Removed sense germinate from word developed\n",
      "Removed sense give-and-take from word discussion\n",
      "Removed sense young_lady from word miss\n",
      "Removed sense Miss from word miss\n",
      "Removed sense misfire from word miss\n",
      "Removed sense missy from word miss\n",
      "Removed sense young_woman from word miss\n",
      "Removed sense Mar from word march\n",
      "Removed sense MArch from word march\n",
      "Removed sense marching from word march\n",
      "Removed sense March from word march\n",
      "Removed sense marching_music from word march\n",
      "Removed sense marchland from word march\n",
      "Removed sense Master_of_Architecture from word march\n",
      "Removed sense border_district from word march\n",
      "Removed sense borderland from word march\n",
      "Removed sense pain_sensation from word pain\n",
      "Removed sense infliction from word pain\n",
      "Removed sense pain_in_the_neck from word pain\n",
      "Removed sense hurting from word pain\n",
      "Removed sense painful_sensation from word pain\n",
      "Removed sense botheration from word pain\n",
      "Removed sense pain_in_the_ass from word pain\n",
      "Removed sense annoyance from word pain\n",
      "Removed sense painfulness from word pain\n",
      "Removed sense high_gear from word high\n",
      "Removed sense senior_high from word high\n",
      "Removed sense high_school from word high\n",
      "Removed sense heights from word high\n",
      "Removed sense highschool from word high\n",
      "Removed sense senior_high_school from word high\n",
      "Removed sense one_C from word hundred\n",
      "Removed sense C from word hundred\n",
      "Removed sense tangency from word contact\n",
      "Removed sense striking from word contact\n",
      "Removed sense impinging from word contact\n",
      "Removed sense contact_lens from word contact\n",
      "Removed sense middleman from word contact\n",
      "Removed sense inter-group_communication from word contact\n",
      "Removed sense physical_contact from word contact\n",
      "Removed sense turn_up from word prove\n",
      "Removed sense try_out from word prove\n",
      "Removed sense turn_out from word prove\n",
      "Removed sense bear_witness from word prove\n",
      "Removed sense shew from word prove\n",
      "Removed sense heating_plant from word heat\n",
      "Removed sense high_temperature from word heat\n",
      "Removed sense heat_energy from word heat\n",
      "Removed sense hotness from word heat\n",
      "Removed sense heating_system from word heat\n",
      "Removed sense oestrus from word heat\n",
      "Removed sense estrus from word heat\n",
      "Removed sense Jesus_Christ from word christ\n",
      "Removed sense Deliverer from word christ\n",
      "Removed sense Christ from word christ\n",
      "Removed sense Saviour from word christ\n",
      "Removed sense Redeemer from word christ\n",
      "Removed sense the_Nazarene from word christ\n",
      "Removed sense Jesus from word christ\n",
      "Removed sense Jesus_of_Nazareth from word christ\n",
      "Removed sense Savior from word christ\n",
      "Removed sense Good_Shepherd from word christ\n",
      "Removed sense free-lance from word independent\n",
      "Removed sense self-employed_person from word independent\n",
      "Removed sense free_lance from word independent\n",
      "Removed sense fencesitter from word independent\n",
      "Removed sense mugwump from word independent\n",
      "Removed sense freelancer from word independent\n",
      "Removed sense psychoanalysis from word analysis\n",
      "Removed sense analytic_thinking from word analysis\n",
      "Removed sense depth_psychology from word analysis\n",
      "Removed sense set_aside from word appropriate\n",
      "Removed sense wondrous from word wonderful\n",
      "Removed sense marvellous from word wonderful\n",
      "Removed sense love_life from word love\n",
      "Removed sense making_love from word love\n",
      "Removed sense erotic_love from word love\n",
      "Removed sense sexual_love from word love\n",
      "Removed sense roll_in_the_hay from word love\n",
      "Removed sense lovemaking from word love\n",
      "Removed sense dearest from word love\n",
      "Removed sense quartern from word fourth\n",
      "Removed sense one-fourth from word fourth\n",
      "Removed sense quaternary from word fourth\n",
      "Removed sense one-quarter from word fourth\n",
      "Removed sense fourth_part from word fourth\n",
      "Removed sense twenty-five_percent from word fourth\n",
      "Removed sense whole_shebang from word works\n",
      "Removed sense whole_kit_and_caboodle from word works\n",
      "Removed sense workings from word works\n",
      "Removed sense kit_and_boodle from word works\n",
      "Removed sense industrial_plant from word works\n",
      "Removed sense body_of_work from word works\n",
      "Removed sense whole_kit from word works\n",
      "Removed sense kit_and_caboodle from word works\n",
      "Removed sense mould from word works\n",
      "Removed sense deeds from word works\n",
      "Removed sense full_treatment from word works\n",
      "Removed sense oeuvre from word works\n",
      "Removed sense whole_kit_and_boodle from word works\n",
      "Removed sense piece_of_work from word works\n",
      "Removed sense whole_caboodle from word works\n",
      "Removed sense whole_works from word works\n",
      "Removed sense mental_faculty from word faculty\n",
      "Removed sense take_over from word assume\n",
      "Removed sense take_up from word assume\n",
      "Removed sense put_on from word assume\n",
      "Removed sense arrogate from word assume\n",
      "Removed sense take_on from word assume\n",
      "Removed sense get_into from word assume\n",
      "Removed sense take_for_granted from word assume\n",
      "Removed sense usurp from word assume\n",
      "Removed sense feign from word assume\n",
      "Removed sense watercourse from word stream\n",
      "Removed sense sound_out from word said\n",
      "Removed sense enjoin from word said\n",
      "Removed sense enunciate from word said\n",
      "Removed sense human_being from word man\n",
      "Removed sense gentleman's_gentleman from word man\n",
      "Removed sense humans from word man\n",
      "Removed sense valet from word man\n",
      "Removed sense human_beings from word man\n",
      "Removed sense Man from word man\n",
      "Removed sense military_personnel from word man\n",
      "Removed sense humankind from word man\n",
      "Removed sense military_man from word man\n",
      "Removed sense adult_male from word man\n",
      "Removed sense Isle_of_Man from word man\n",
      "Removed sense serviceman from word man\n",
      "Removed sense valet_de_chambre from word man\n",
      "Removed sense human_race from word man\n",
      "Removed sense human_body from word flesh\n",
      "Removed sense chassis from word flesh\n",
      "Removed sense physique from word flesh\n",
      "Removed sense material_body from word flesh\n",
      "Removed sense physical_body from word flesh\n",
      "Removed sense favourable_reception from word approval\n",
      "Removed sense favorable_reception from word approval\n",
      "Removed sense metrical_unit from word feet\n",
      "Removed sense invertebrate_foot from word feet\n",
      "Removed sense animal_foot from word feet\n",
      "Removed sense human_foot from word feet\n",
      "Removed sense understructure from word feet\n",
      "Removed sense metrical_foot from word feet\n",
      "Removed sense groundwork from word feet\n",
      "Removed sense substructure from word feet\n",
      "Removed sense responsibleness from word responsibility\n",
      "Removed sense English from word english\n",
      "Removed sense English_people from word english\n",
      "Removed sense English_language from word english\n",
      "Removed sense noblewoman from word lady\n",
      "Removed sense Lady from word lady\n",
      "Removed sense gentlewoman from word lady\n",
      "Removed sense peeress from word lady\n",
      "Removed sense downcast from word down\n",
      "Removed sense down_feather from word down\n",
      "Removed sense Down from word down\n",
      "Removed sense John_L._H._Down from word down\n",
      "Removed sense midriff from word middle\n",
      "Removed sense midsection from word middle\n",
      "Removed sense Federal_soldier from word federal\n",
      "Removed sense Union from word federal\n",
      "Removed sense Federal from word federal\n",
      "Removed sense Fed from word federal\n",
      "Removed sense federal_official from word federal\n",
      "Removed sense Union_soldier from word federal\n",
      "Removed sense let_in from word include\n",
      "Removed sense enquiry from word research\n",
      "Removed sense St._David from word david\n",
      "Removed sense Saint_David from word david\n",
      "Removed sense Jacques_Louis_David from word david\n",
      "Removed sense David from word david\n",
      "Removed sense roll_in_the_hay from word knowing\n",
      "Removed sense achiever from word success\n",
      "Removed sense succeeder from word success\n",
      "Removed sense minuscule from word little\n",
      "Removed sense lilliputian from word little\n",
      "Removed sense signaling from word signal\n",
      "Removed sense HQ from word headquarters\n",
      "Removed sense home_base from word headquarters\n",
      "Removed sense central_office from word headquarters\n",
      "Removed sense military_headquarters from word headquarters\n",
      "Removed sense main_office from word headquarters\n",
      "Removed sense home_office from word headquarters\n",
      "Removed sense coordination_compound from word complex\n",
      "Removed sense building_complex from word complex\n",
      "Removed sense get-go from word beginning\n",
      "Removed sense rootage from word beginning\n",
      "Removed sense commencement from word beginning\n",
      "Removed sense starting_time from word beginning\n",
      "Removed sense showtime from word beginning\n",
      "Removed sense kickoff from word beginning\n",
      "Removed sense theatrical_role from word role\n",
      "Removed sense Night from word night\n",
      "Removed sense Nox from word night\n",
      "Removed sense nighttime from word night\n",
      "Removed sense activeness from word activity\n",
      "Removed sense natural_action from word activity\n",
      "Removed sense body_process from word activity\n",
      "Removed sense bodily_process from word activity\n",
      "Removed sense bodily_function from word activity\n",
      "Removed sense natural_process from word activity\n",
      "Removed sense LED from word led\n",
      "Removed sense light-emitting_diode from word led\n",
      "Removed sense particular_proposition from word particular\n",
      "Removed sense critical_review from word review\n",
      "Removed sense reassessment from word review\n",
      "Removed sense reexamination from word review\n",
      "Removed sense reappraisal from word review\n",
      "Removed sense revaluation from word review\n",
      "Removed sense followup from word review\n",
      "Removed sense recapitulation from word review\n",
      "Removed sense limited_review from word review\n",
      "Removed sense revue from word review\n",
      "Removed sense review_article from word review\n",
      "Removed sense brushup from word review\n",
      "Removed sense take_into_account from word allow\n",
      "Removed sense allow_for from word allow\n",
      "Removed sense give_up from word allow\n",
      "Removed sense set_aside from word allow\n",
      "Removed sense enquire from word asked\n",
      "Removed sense necessitate from word asked\n",
      "Removed sense call_for from word asked\n",
      "Removed sense overcompensate from word covered\n",
      "Removed sense cut_across from word covered\n",
      "Removed sense pass_over from word covered\n",
      "Removed sense cut_through from word covered\n",
      "Removed sense get_across from word covered\n",
      "Removed sense incubate from word covered\n",
      "Removed sense spread_over from word covered\n",
      "Removed sense get_over from word covered\n",
      "Removed sense cover_up from word covered\n",
      "Removed sense wrap_up from word covered\n",
      "Removed sense enshroud from word covered\n",
      "Removed sense running_play from word runs\n",
      "Removed sense footrace from word runs\n",
      "Removed sense foot_race from word runs\n",
      "Removed sense black_market from word runs\n",
      "Removed sense streamlet from word runs\n",
      "Removed sense political_campaign from word runs\n",
      "Removed sense runnel from word runs\n",
      "Removed sense running_game from word runs\n",
      "Removed sense outpouring from word runs\n",
      "Removed sense rivulet from word runs\n",
      "Removed sense black_Maria from word wagon\n",
      "Removed sense Big_Dipper from word wagon\n",
      "Removed sense estate_car from word wagon\n",
      "Removed sense Wain from word wagon\n",
      "Removed sense coaster_wagon from word wagon\n",
      "Removed sense waggon from word wagon\n",
      "Removed sense Wagon from word wagon\n",
      "Removed sense station_waggon from word wagon\n",
      "Removed sense paddy_wagon from word wagon\n",
      "Removed sense Dipper from word wagon\n",
      "Removed sense Plough from word wagon\n",
      "Removed sense beach_waggon from word wagon\n",
      "Removed sense patrol_wagon from word wagon\n",
      "Removed sense police_wagon from word wagon\n",
      "Removed sense beach_wagon from word wagon\n",
      "Removed sense police_van from word wagon\n",
      "Removed sense Charles's_Wain from word wagon\n",
      "Removed sense station_wagon from word wagon\n",
      "Removed sense tribulation from word trial\n",
      "Removed sense visitation from word trial\n",
      "Removed sense trial_run from word trial\n",
      "Removed sense tryout from word trial\n",
      "Removed sense go_against from word broke\n",
      "Removed sense transgress from word broke\n",
      "Removed sense snap_off from word broke\n",
      "Removed sense fall_apart from word broke\n",
      "Removed sense break_down from word broke\n",
      "Removed sense kick_downstairs from word broke\n",
      "Removed sense break_out from word broke\n",
      "Removed sense divulge from word broke\n",
      "Removed sense come_apart from word broke\n",
      "Removed sense give_way from word broke\n",
      "Removed sense bring_out from word broke\n",
      "Removed sense break_up from word broke\n",
      "Removed sense break_in from word broke\n",
      "Removed sense unwrap from word broke\n",
      "Removed sense discontinue from word broke\n",
      "Removed sense get_around from word broke\n",
      "Removed sense give_out from word broke\n",
      "Removed sense break-dance from word broke\n",
      "Removed sense break_away from word broke\n",
      "Removed sense recrudesce from word broke\n",
      "Removed sense break_off from word broke\n",
      "Removed sense give_away from word broke\n",
      "Removed sense demote from word broke\n",
      "Removed sense infract from word broke\n",
      "Removed sense conk_out from word broke\n",
      "Removed sense let_on from word broke\n",
      "Removed sense go_bad from word broke\n",
      "Removed sense let_out from word broke\n",
      "Removed sense wear_out from word broke\n",
      "Removed sense relegate from word broke\n",
      "Removed sense get_out from word broke\n",
      "Removed sense fall_in from word broke\n",
      "Removed sense eternal_sleep from word sleep\n",
      "Removed sense sopor from word sleep\n",
      "Removed sense eternal_rest from word sleep\n",
      "Removed sense quietus from word sleep\n",
      "Removed sense pursual from word following\n",
      "Removed sense followers from word following\n",
      "Removed sense contract_bridge from word contract\n",
      "Removed sense British from word british\n",
      "Removed sense British_people from word british\n",
      "Removed sense Brits from word british\n",
      "Removed sense German_mark from word mark\n",
      "Removed sense bell_ringer from word mark\n",
      "Removed sense marking from word mark\n",
      "Removed sense chump from word mark\n",
      "Removed sense Deutschmark from word mark\n",
      "Removed sense Deutsche_Mark from word mark\n",
      "Removed sense soft_touch from word mark\n",
      "Removed sense St._Mark from word mark\n",
      "Removed sense crisscross from word mark\n",
      "Removed sense fall_guy from word mark\n",
      "Removed sense home_run from word mark\n",
      "Removed sense Mark from word mark\n",
      "Removed sense stigma from word mark\n",
      "Removed sense bull's_eye from word mark\n",
      "Removed sense Saint_Mark from word mark\n",
      "Removed sense Gospel_According_to_Mark from word mark\n",
      "Removed sense ADD from word add\n",
      "Removed sense ADHD from word add\n",
      "Removed sense minimal_brain_damage from word add\n",
      "Removed sense attention_deficit_disorder from word add\n",
      "Removed sense MBD from word add\n",
      "Removed sense hyperkinetic_syndrome from word add\n",
      "Removed sense attention_deficit_hyperactivity_disorder from word add\n",
      "Removed sense minimal_brain_dysfunction from word add\n",
      "Removed sense bottomland from word bottom\n",
      "Removed sense bottom_of_the_inning from word bottom\n",
      "Removed sense freighter from word bottom\n",
      "Removed sense buttocks from word bottom\n",
      "Removed sense derriere from word bottom\n",
      "Removed sense tail_end from word bottom\n",
      "Removed sense keister from word bottom\n",
      "Removed sense posterior from word bottom\n",
      "Removed sense buns from word bottom\n",
      "Removed sense undersurface from word bottom\n",
      "Removed sense backside from word bottom\n",
      "Removed sense merchant_ship from word bottom\n",
      "Removed sense merchantman from word bottom\n",
      "Removed sense hindquarters from word bottom\n",
      "Removed sense tooshie from word bottom\n",
      "Removed sense tush from word bottom\n",
      "Removed sense nates from word bottom\n",
      "Removed sense hind_end from word bottom\n",
      "Removed sense rear_end from word bottom\n",
      "Removed sense modern_font from word modern\n",
      "Removed sense Bodoni from word modern\n",
      "Removed sense Bodoni_font from word modern\n",
      "Removed sense Modern from word modern\n",
      "Removed sense cognitive_content from word content\n",
      "Removed sense contentedness from word content\n",
      "Removed sense subject_matter from word content\n",
      "Removed sense mental_object from word content\n",
      "Removed sense depicted_object from word content\n",
      "Removed sense Bharat from word india\n",
      "Removed sense Republic_of_India from word india\n",
      "Removed sense India from word india\n",
      "Removed sense Quaker from word friend\n",
      "Removed sense protagonist from word friend\n",
      "Removed sense Friend from word friend\n",
      "Removed sense Lashkar-e-Tayyiba from word let\n",
      "Removed sense net_ball from word let\n",
      "Removed sense countenance from word let\n",
      "Removed sense LET from word let\n",
      "Removed sense Lashkar-e-Taiba from word let\n",
      "Removed sense Lashkar-e-Toiba from word let\n",
      "Removed sense Army_of_the_Righteous from word let\n",
      "Removed sense Army_of_the_Pure from word let\n",
      "Removed sense praxis from word practice\n",
      "Removed sense practice_session from word practice\n",
      "Removed sense recitation from word practice\n",
      "Removed sense victimization from word using\n",
      "Removed sense victimisation from word using\n",
      "Removed sense square_up from word determine\n",
      "Removed sense square_off from word determine\n",
      "Removed sense find_out from word determine\n",
      "Removed sense make_up_one's_mind from word determine\n",
      "Removed sense groundwork from word basis\n",
      "Removed sense cornerstone from word basis\n",
      "Removed sense arcsecond from word second\n",
      "Removed sense second_base from word second\n",
      "Removed sense indorsement from word second\n",
      "Removed sense second_gear from word second\n",
      "Removed sense secondment from word second\n",
      "Removed sense resolving from word resolution\n",
      "Removed sense solvent from word resolution\n",
      "Removed sense resolving_power from word resolution\n",
      "Removed sense firmness_of_purpose from word resolution\n",
      "Removed sense firmness from word resolution\n",
      "Removed sense resoluteness from word resolution\n",
      "Removed sense solving from word resolution\n",
      "Removed sense Sat from word sat\n",
      "Removed sense Sabbatum from word sat\n",
      "Removed sense Saturday from word sat\n",
      "Removed sense text_edition from word text\n",
      "Removed sense school_text from word text\n",
      "Removed sense schoolbook from word text\n",
      "Removed sense textual_matter from word text\n",
      "Removed sense billet from word place\n",
      "Removed sense shoes from word place\n",
      "Removed sense topographic_point from word place\n",
      "Removed sense blank_space from word place\n",
      "Removed sense E from word east\n",
      "Removed sense East from word east\n",
      "Removed sense Orient from word east\n",
      "Removed sense eastern_United_States from word east\n",
      "Removed sense due_east from word east\n",
      "Removed sense harmonise from word agree\n",
      "Removed sense harmonize from word agree\n",
      "Removed sense fit_in from word agree\n",
      "Removed sense garden_truck from word produce\n",
      "Removed sense green_goods from word produce\n",
      "Removed sense green_groceries from word produce\n",
      "Removed sense distich from word pair\n",
      "Removed sense duad from word pair\n",
      "Removed sense yoke from word pair\n",
      "Removed sense dyad from word pair\n",
      "Removed sense twosome from word pair\n",
      "Removed sense duet from word pair\n",
      "Removed sense geminate from word pair\n",
      "Removed sense couplet from word pair\n",
      "Removed london with synonyms dict_keys([])\n",
      "Removed medical with synonyms dict_keys([])\n",
      "Removed device with synonyms dict_keys(['twist'])\n",
      "Removed forth with synonyms dict_keys(['forward'])\n",
      "Removed party with synonyms dict_keys(['company'])\n",
      "Removed la with synonyms dict_keys(['lah'])\n",
      "Removed unique with synonyms dict_keys(['alone'])\n",
      "Removed unable with synonyms dict_keys(['ineffective'])\n",
      "Removed joseph with synonyms dict_keys([])\n",
      "Removed military with synonyms dict_keys([])\n",
      "Removed planned with synonyms dict_keys(['contrive'])\n",
      "Removed america with synonyms dict_keys([])\n",
      "Removed career with synonyms dict_keys(['vocation'])\n",
      "Removed truth with synonyms dict_keys(['accuracy'])\n",
      "Removed friday with synonyms dict_keys([])\n",
      "Removed high with synonyms dict_keys([])\n",
      "Removed christ with synonyms dict_keys(['messiah'])\n",
      "Removed analysis with synonyms dict_keys([])\n",
      "Removed fourth with synonyms dict_keys(['quarter'])\n",
      "Removed english with synonyms dict_keys(['side'])\n",
      "Removed federal with synonyms dict_keys([])\n",
      "Removed include with synonyms dict_keys(['admit'])\n",
      "Removed david with synonyms dict_keys([])\n",
      "Removed success with synonyms dict_keys(['winner'])\n",
      "Removed headquarters with synonyms dict_keys([])\n",
      "Removed complex with synonyms dict_keys(['composite'])\n",
      "Removed night with synonyms dict_keys(['dark'])\n",
      "Removed activity with synonyms dict_keys(['action'])\n",
      "Removed wagon with synonyms dict_keys([])\n",
      "Removed british with synonyms dict_keys([])\n",
      "Removed modern with synonyms dict_keys(['mod'])\n",
      "Removed india with synonyms dict_keys([])\n",
      "Removed text with synonyms dict_keys(['textbook'])\n",
      "Removed east with synonyms dict_keys(['eastward'])\n",
      "Removed 34 words\n"
     ]
    }
   ],
   "source": [
    "# # remove senses that have less than 30 sentences and limit the number of sentences to 100\n",
    "# for word in list(word_synonym_sentences.keys()):\n",
    "#     senses = word_synonym_sentences[word]\n",
    "#     for sense, sentences in senses.items():\n",
    "#         if len(sentences) < 30:\n",
    "#             word_synonym_sentences[word].pop(sense)\n",
    "#             print(f\"Removed sense {sense} from word {word}\")\n",
    "#         else:\n",
    "#             word_synonym_sentences[word][sense] = sentences[:100]\n",
    "            \n",
    "# # remove any words that have less than 2 synonyms\n",
    "# for word in list(word_synonym_sentences.keys()):\n",
    "#     synonyms = word_synonyms[word]\n",
    "#     if len(synonyms) < 2:\n",
    "#         word_synonym_sentences.pop(word)\n",
    "#         word_synonyms.pop(word)\n",
    "#         final_words.remove(word)\n",
    "#         print(f\"Removed {word} with synonyms {synonyms}\")\n",
    "        \n",
    "# Remove senses that have less than 30 sentences and limit the number of sentences to 100\n",
    "for word in list(word_synonym_sentences.keys()):\n",
    "    senses = word_synonym_sentences[word]\n",
    "    senses_to_remove = []\n",
    "    for sense in list(senses.keys()):\n",
    "        sentences = senses[sense]\n",
    "        if len(sentences) < 30:\n",
    "            senses_to_remove.append(sense)\n",
    "            print(f\"Removed sense {sense} from word {word}\")\n",
    "        else:\n",
    "            senses[sense] = sentences[:100]  # Limit to 100 sentences\n",
    "    # Remove senses after iteration\n",
    "    for sense in senses_to_remove:\n",
    "        senses.pop(sense)\n",
    "\n",
    "# Remove any words that have less than 2 synonyms\n",
    "words_to_remove = []\n",
    "for word in list(word_synonym_sentences.keys()):\n",
    "    synonyms = word_synonym_sentences[word]\n",
    "    if len(synonyms) < 2:\n",
    "        words_to_remove.append(word)\n",
    "        word_synonyms.pop(word)\n",
    "        final_words.remove(word)\n",
    "        # word_synonym_sentences.pop(word)\n",
    "        word_sentences.pop(word, None)\n",
    "        print(f\"Removed {word} with synonyms {synonyms.keys()}\")\n",
    "\n",
    "print(f\"Removed {len(words_to_remove)} words\")\n",
    "# Remove words after iteration\n",
    "for word in words_to_remove:\n",
    "    word_synonym_sentences.pop(word)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102 102 102 102\n"
     ]
    }
   ],
   "source": [
    "print(len(word_synonym_sentences), len(word_synonyms), len(final_words), len(word_sentences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         word  start  end                                           sentence  \\\n",
      "0      regard    156  162  go ahead and make your point ' about the mello...   \n",
      "1      regard    238  244  laughlin 's category encompass blind including...   \n",
      "2      regard     15   21  but if he have regard the advice of never let ...   \n",
      "3      regard     32   38  i be unaware that the e be must regard court o...   \n",
      "4      regard      0    6  regard this advice strauss quickly set up a sm...   \n",
      "...       ...    ...  ...                                                ...   \n",
      "50965    pair     28   32  the view and vino-a perfect pair on the deck a...   \n",
      "50966    pair    189  193  england do not release ' natural born killer '...   \n",
      "50967    pair     27   31  in a happily time move the pair raise master g...   \n",
      "50968    pair    297  301  in answer jaina increase the magnification on ...   \n",
      "50969    pair     88   92  the arrangement suit neither and each be busy ...   \n",
      "\n",
      "       sense pos_tag original_sense  \n",
      "0          1      VB           heed  \n",
      "1          1      NN           heed  \n",
      "2          1     VBN           heed  \n",
      "3          1      VB           heed  \n",
      "4          1      NN           heed  \n",
      "...      ...     ...            ...  \n",
      "50965      0      NN           pair  \n",
      "50966      0      NN           pair  \n",
      "50967      0      NN           pair  \n",
      "50968      0      NN           pair  \n",
      "50969      0     VBN           pair  \n",
      "\n",
      "[50970 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import re\n",
    "# import nltk\n",
    "# from nltk.tokenize import TreebankWordTokenizer\n",
    "# from nltk import pos_tag\n",
    "# from nltk.corpus import wordnet as wn\n",
    "# from collections import Counter\n",
    "\n",
    "# # Download NLTK data files if not already downloaded\n",
    "# nltk.download('punkt', quiet=True)\n",
    "# nltk.download('averaged_perceptron_tagger', quiet=True)\n",
    "\n",
    "# # Initialize the tokenizer\n",
    "# tokenizer = TreebankWordTokenizer()\n",
    "\n",
    "# # Assume word_synonym_sentences and word_sentences are already defined\n",
    "# # Example structures:\n",
    "# # word_synonym_sentences = {\n",
    "# #     'word1': {'synonym1': ['sentence1', 'sentence2'], 'synonym2': ['sentence3']},\n",
    "# #     'word2': {'synonym3': ['sentence4'], 'synonym4': ['sentence5']}\n",
    "# # }\n",
    "# # word_sentences = {'word1': ['sentence6', 'sentence7'], 'word2': ['sentence8']}\n",
    "\n",
    "# # Initialize the data list\n",
    "# data = []\n",
    "\n",
    "# # Function to get the POS tag of the word in context\n",
    "# def get_pos_tag(word, sentence, start, end):\n",
    "#     word_in_sentence = sentence[start:end]\n",
    "#     tokens = tokenizer.tokenize(sentence)\n",
    "#     pos_tags = pos_tag(tokens)\n",
    "#     # Reconstruct the sentence from tokens to get spans\n",
    "#     current_pos = 0\n",
    "#     for idx, token in enumerate(tokens):\n",
    "#         # Find the start and end positions of each token\n",
    "#         token_start = sentence.find(token, current_pos)\n",
    "#         token_end = token_start + len(token)\n",
    "#         current_pos = token_end\n",
    "#         if token_start == start and token_end == end:\n",
    "#             return pos_tags[idx][1]\n",
    "#     return 'UNKNOWN'\n",
    "\n",
    "\n",
    "\n",
    "# # Process each word\n",
    "# for word in word_synonym_sentences:\n",
    "#     synonyms_dict = word_synonym_sentences[word]\n",
    "#     synonyms_list = list(synonyms_dict.keys())  # List of synonyms\n",
    "#     # Map synonyms to sense numbers starting from 1\n",
    "#     synonym_sense_mapping = {synonym: idx+1 for idx, synonym in enumerate(synonyms_list)}\n",
    "#     # Process sentences from synonyms\n",
    "#     for synonym in synonyms_list:\n",
    "#         sense = synonym_sense_mapping[synonym]\n",
    "#         sentences = synonyms_dict[synonym]\n",
    "#         for sentence in sentences:\n",
    "#             # Replace the synonym with the word in the sentence\n",
    "#             pattern = r'\\b{}\\b'.format(re.escape(synonym))\n",
    "#             replaced_sentence = re.sub(pattern, word, sentence)\n",
    "#             # Tokenize the replaced sentence and get spans\n",
    "#             tokens = tokenizer.tokenize(replaced_sentence)\n",
    "#             spans = list(tokenizer.span_tokenize(replaced_sentence))\n",
    "#             pos_tags = pos_tag(tokens)\n",
    "#             # Find tokens that match the word\n",
    "#             for idx, (token, (start, end)) in enumerate(zip(tokens, spans)):\n",
    "#                 if token.lower() == word.lower():\n",
    "#                     pos_tag_token = pos_tags[idx][1]\n",
    "#                     data.append({\n",
    "#                         'word': word,\n",
    "#                         'start': start,\n",
    "#                         'end': end,\n",
    "#                         'sentence': replaced_sentence,\n",
    "#                         'sense': sense,\n",
    "#                         'pos_tag': pos_tag_token\n",
    "#                     })\n",
    "#     # Process sentences from word_sentences[word] with sense 0\n",
    "#     sense = 0\n",
    "#     sentences = word_sentences.get(word, [])\n",
    "#     for sentence in sentences:\n",
    "#         # Tokenize the sentence and get spans\n",
    "#         tokens = tokenizer.tokenize(sentence)\n",
    "#         spans = list(tokenizer.span_tokenize(sentence))\n",
    "#         pos_tags = pos_tag(tokens)\n",
    "#         # Find tokens that match the word\n",
    "#         for idx, (token, (start, end)) in enumerate(zip(tokens, spans)):\n",
    "#             if token.lower() == word.lower():\n",
    "#                 pos_tag_token = pos_tags[idx][1]\n",
    "#                 data.append({\n",
    "#                     'word': word,\n",
    "#                     'start': start,\n",
    "#                     'end': end,\n",
    "#                     'sentence': sentence,\n",
    "#                     'sense': sense,\n",
    "#                     'pos_tag': pos_tag_token\n",
    "#                 })\n",
    "\n",
    "# # Create the DataFrame\n",
    "# df = pd.DataFrame(data, columns=['word', 'start', 'end', 'sentence', 'sense', 'pos_tag'])\n",
    "\n",
    "# # Display the DataFrame\n",
    "# print(df)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk import pos_tag\n",
    "\n",
    "# Download NLTK data files if not already downloaded\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "\n",
    "# Assume word_synonym_sentences and word_sentences are already defined\n",
    "# Example structures:\n",
    "# word_synonym_sentences = {\n",
    "#     'word1': {'synonym1': ['sentence1', 'sentence2'], 'synonym2': ['sentence3']},\n",
    "#     'word2': {'synonym3': ['sentence4'], 'synonym4': ['sentence5']}\n",
    "# }\n",
    "# word_sentences = {'word1': ['sentence6', 'sentence7'], 'word2': ['sentence8']}\n",
    "\n",
    "# Initialize the data list\n",
    "data = []\n",
    "\n",
    "# Process each word\n",
    "for word in word_synonym_sentences:\n",
    "    synonyms_dict = word_synonym_sentences[word]\n",
    "    synonyms_list = list(synonyms_dict.keys())  # List of synonyms\n",
    "    # Map synonyms to sense numbers starting from 1\n",
    "    synonym_sense_mapping = {synonym: idx+1 for idx, synonym in enumerate(synonyms_list)}\n",
    "    # Process sentences from synonyms\n",
    "    for synonym in synonyms_list:\n",
    "        sense = synonym_sense_mapping[synonym]\n",
    "        sentences = synonyms_dict[synonym]\n",
    "        for sentence in sentences:\n",
    "            # Replace the synonym with the word in the sentence\n",
    "            pattern = r'\\b{}\\b'.format(re.escape(synonym))\n",
    "            replaced_sentence = re.sub(pattern, word, sentence)\n",
    "            # Tokenize the replaced sentence and get spans\n",
    "            tokens = tokenizer.tokenize(replaced_sentence)\n",
    "            spans = list(tokenizer.span_tokenize(replaced_sentence))\n",
    "            pos_tags = pos_tag(tokens)\n",
    "            # Find tokens that match the word\n",
    "            for idx, (token, (start, end)) in enumerate(zip(tokens, spans)):\n",
    "                if token.lower() == word.lower():\n",
    "                    pos_tag_token = pos_tags[idx][1]\n",
    "                    data.append({\n",
    "                        'word': word,\n",
    "                        'start': start,\n",
    "                        'end': end,\n",
    "                        'sentence': replaced_sentence,\n",
    "                        'sense': sense,\n",
    "                        'pos_tag': pos_tag_token,\n",
    "                        'original_sense': synonym  \n",
    "                    })\n",
    "    # Process sentences from word_sentences[word] with sense 0\n",
    "    sense = 0\n",
    "    sentences = word_sentences.get(word, [])\n",
    "    for sentence in sentences:\n",
    "        # Tokenize the sentence and get spans\n",
    "        tokens = tokenizer.tokenize(sentence)\n",
    "        spans = list(tokenizer.span_tokenize(sentence))\n",
    "        pos_tags = pos_tag(tokens)\n",
    "        # Find tokens that match the word\n",
    "        for idx, (token, (start, end)) in enumerate(zip(tokens, spans)):\n",
    "            if token.lower() == word.lower():\n",
    "                pos_tag_token = pos_tags[idx][1]\n",
    "                data.append({\n",
    "                    'word': word,\n",
    "                    'start': start,\n",
    "                    'end': end,\n",
    "                    'sentence': sentence,\n",
    "                    'sense': sense,\n",
    "                    'pos_tag': pos_tag_token,\n",
    "                    'original_sense': word  \n",
    "                })\n",
    "\n",
    "# Create the DataFrame\n",
    "df = pd.DataFrame(data, columns=['word', 'start', 'end', 'sentence', 'sense', 'pos_tag', 'original_sense'])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "sense\n",
      "2     6844\n",
      "1     6606\n",
      "0     6583\n",
      "3     5735\n",
      "4     5090\n",
      "5     3927\n",
      "6     2963\n",
      "7     2179\n",
      "8     1691\n",
      "9     1379\n",
      "10    1227\n",
      "13     918\n",
      "11     913\n",
      "12     904\n",
      "14     377\n",
      "21     374\n",
      "20     321\n",
      "23     308\n",
      "19     306\n",
      "18     290\n",
      "17     273\n",
      "16     267\n",
      "25     207\n",
      "22     199\n",
      "26     159\n",
      "15     153\n",
      "27     145\n",
      "24     144\n",
      "28     116\n",
      "29     101\n",
      "31      93\n",
      "35      78\n",
      "33      38\n",
      "32      34\n",
      "36      20\n",
      "34       8\n",
      "Name: count, dtype: int64\n",
      "pos_tag\n",
      "NN     22702\n",
      "JJ      6826\n",
      "VB      4809\n",
      "VBN     4623\n",
      "VBG     3321\n",
      "VBD     2617\n",
      "NNS     2177\n",
      "VBP     1624\n",
      "VBZ     1395\n",
      "IN       229\n",
      "RP       216\n",
      "RB       154\n",
      "JJS      140\n",
      "CD        75\n",
      "PDT       16\n",
      "FW        10\n",
      "CC         7\n",
      "$          6\n",
      "JJR        5\n",
      "SYM        4\n",
      "MD         3\n",
      "RBR        2\n",
      "DT         2\n",
      "PRP        2\n",
      "NNP        2\n",
      "RBS        1\n",
      "WP         1\n",
      "UH         1\n",
      "Name: count, dtype: int64\n",
      "102\n",
      "Number of words without sense 0: 14\n"
     ]
    }
   ],
   "source": [
    "# check how many rows have start -1, should be 0\n",
    "print(len(df[df['start'] == -1]))\n",
    "\n",
    "# check the distribution of senses\n",
    "print(df['sense'].value_counts())\n",
    "\n",
    "# check the distribution of pos tags\n",
    "print(df['pos_tag'].value_counts())\n",
    "\n",
    "# check the distribution of words\n",
    "print(df['word'].nunique())\n",
    "\n",
    "# check how many words don't have sense 0\n",
    "all_words = set(df['word'])\n",
    "words_with_sense0 = set(df[df['sense'] == 0]['word'])\n",
    "words_without_sense0 = all_words - words_with_sense0\n",
    "print(f\"Number of words without sense 0: {len(words_without_sense0)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>sentence</th>\n",
       "      <th>sense</th>\n",
       "      <th>pos_tag</th>\n",
       "      <th>original_sense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>regard</td>\n",
       "      <td>156</td>\n",
       "      <td>162</td>\n",
       "      <td>go ahead and make your point ' about the mello...</td>\n",
       "      <td>1</td>\n",
       "      <td>VB</td>\n",
       "      <td>heed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>regard</td>\n",
       "      <td>238</td>\n",
       "      <td>244</td>\n",
       "      <td>laughlin 's category encompass blind including...</td>\n",
       "      <td>1</td>\n",
       "      <td>NN</td>\n",
       "      <td>heed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>regard</td>\n",
       "      <td>15</td>\n",
       "      <td>21</td>\n",
       "      <td>but if he have regard the advice of never let ...</td>\n",
       "      <td>1</td>\n",
       "      <td>VBN</td>\n",
       "      <td>heed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>regard</td>\n",
       "      <td>32</td>\n",
       "      <td>38</td>\n",
       "      <td>i be unaware that the e be must regard court o...</td>\n",
       "      <td>1</td>\n",
       "      <td>VB</td>\n",
       "      <td>heed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>regard</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>regard this advice strauss quickly set up a sm...</td>\n",
       "      <td>1</td>\n",
       "      <td>NN</td>\n",
       "      <td>heed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50965</th>\n",
       "      <td>pair</td>\n",
       "      <td>28</td>\n",
       "      <td>32</td>\n",
       "      <td>the view and vino-a perfect pair on the deck a...</td>\n",
       "      <td>0</td>\n",
       "      <td>NN</td>\n",
       "      <td>pair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50966</th>\n",
       "      <td>pair</td>\n",
       "      <td>189</td>\n",
       "      <td>193</td>\n",
       "      <td>england do not release ' natural born killer '...</td>\n",
       "      <td>0</td>\n",
       "      <td>NN</td>\n",
       "      <td>pair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50967</th>\n",
       "      <td>pair</td>\n",
       "      <td>27</td>\n",
       "      <td>31</td>\n",
       "      <td>in a happily time move the pair raise master g...</td>\n",
       "      <td>0</td>\n",
       "      <td>NN</td>\n",
       "      <td>pair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50968</th>\n",
       "      <td>pair</td>\n",
       "      <td>297</td>\n",
       "      <td>301</td>\n",
       "      <td>in answer jaina increase the magnification on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NN</td>\n",
       "      <td>pair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50969</th>\n",
       "      <td>pair</td>\n",
       "      <td>88</td>\n",
       "      <td>92</td>\n",
       "      <td>the arrangement suit neither and each be busy ...</td>\n",
       "      <td>0</td>\n",
       "      <td>VBN</td>\n",
       "      <td>pair</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50970 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         word  start  end                                           sentence  \\\n",
       "0      regard    156  162  go ahead and make your point ' about the mello...   \n",
       "1      regard    238  244  laughlin 's category encompass blind including...   \n",
       "2      regard     15   21  but if he have regard the advice of never let ...   \n",
       "3      regard     32   38  i be unaware that the e be must regard court o...   \n",
       "4      regard      0    6  regard this advice strauss quickly set up a sm...   \n",
       "...       ...    ...  ...                                                ...   \n",
       "50965    pair     28   32  the view and vino-a perfect pair on the deck a...   \n",
       "50966    pair    189  193  england do not release ' natural born killer '...   \n",
       "50967    pair     27   31  in a happily time move the pair raise master g...   \n",
       "50968    pair    297  301  in answer jaina increase the magnification on ...   \n",
       "50969    pair     88   92  the arrangement suit neither and each be busy ...   \n",
       "\n",
       "       sense pos_tag original_sense  \n",
       "0          1      VB           heed  \n",
       "1          1      NN           heed  \n",
       "2          1     VBN           heed  \n",
       "3          1      VB           heed  \n",
       "4          1      NN           heed  \n",
       "...      ...     ...            ...  \n",
       "50965      0      NN           pair  \n",
       "50966      0      NN           pair  \n",
       "50967      0      NN           pair  \n",
       "50968      0      NN           pair  \n",
       "50969      0     VBN           pair  \n",
       "\n",
       "[50970 rows x 7 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep_df = df\n",
    "keep_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50970\n",
      "Word 'regard' has more than 5 senses: 9\n",
      "Word 'coming' has less than 30 sentences for sense 0: 4\n",
      "Word 'forest' has less than 30 sentences for sense 3: 1\n",
      "Word 'formed' has less than 30 sentences for sense 0: 0\n",
      "Word 'expected' has less than 30 sentences for sense 0: 0\n",
      "Word 'broken' has less than 30 sentences for sense 7: 28\n",
      "Word 'broken' has more than 5 senses: 13\n",
      "Word 'understanding' has less than 30 sentences for sense 2: 13\n",
      "Word 'understanding' has less than 30 sentences for sense 4: 25\n",
      "Word 'understanding' has more than 5 senses: 9\n",
      "Word 'being' has more than 5 senses: 6\n",
      "Word 'united' has less than 30 sentences for sense 1: 8\n",
      "Word 'united' has less than 30 sentences for sense 2: 29\n",
      "Word 'train' has less than 30 sentences for sense 4: 28\n",
      "Word 'train' has more than 5 senses: 14\n",
      "Word 'move' has less than 30 sentences for sense 5: 28\n",
      "Word 'move' has less than 30 sentences for sense 8: 8\n",
      "Word 'move' has more than 5 senses: 11\n",
      "Word 'single' has less than 30 sentences for sense 3: 3\n",
      "Word 'single' has less than 30 sentences for sense 4: 9\n",
      "Word 'single' has less than 30 sentences for sense 6: 1\n",
      "Word 'single' has more than 5 senses: 7\n",
      "Word 'project' has less than 30 sentences for sense 6: 26\n",
      "Word 'project' has more than 5 senses: 14\n",
      "Word 'club' has less than 30 sentences for sense 8: 11\n",
      "Word 'club' has more than 5 senses: 9\n",
      "Word 'given' has less than 30 sentences for sense 0: 4\n",
      "Word 'horses' has less than 30 sentences for sense 0: 1\n",
      "Word 'open' has more than 5 senses: 7\n",
      "Word 'added' has less than 30 sentences for sense 0: 0\n",
      "Word 'child' has more than 5 senses: 6\n",
      "Word 'company' has more than 5 senses: 8\n",
      "Word 'rule' has less than 30 sentences for sense 5: 11\n",
      "Word 'rule' has less than 30 sentences for sense 13: 19\n",
      "Word 'rule' has more than 5 senses: 13\n",
      "Word 'present' has less than 30 sentences for sense 2: 2\n",
      "Word 'present' has less than 30 sentences for sense 11: 7\n",
      "Word 'present' has more than 5 senses: 12\n",
      "Word 'authority' has more than 5 senses: 8\n",
      "Word 'concerning' has less than 30 sentences for sense 3: 17\n",
      "Word 'developed' has less than 30 sentences for sense 0: 0\n",
      "Word 'miss' has less than 30 sentences for sense 0: 26\n",
      "Word 'march' has less than 30 sentences for sense 3: 7\n",
      "Word 'march' has more than 5 senses: 7\n",
      "Word 'pain' has less than 30 sentences for sense 0: 27\n",
      "Word 'contact' has more than 5 senses: 6\n",
      "Word 'heat' has less than 30 sentences for sense 4: 2\n",
      "Word 'heat' has more than 5 senses: 6\n",
      "Word 'independent' has less than 30 sentences for sense 3: 28\n",
      "Word 'love' has less than 30 sentences for sense 4: 13\n",
      "Word 'love' has more than 5 senses: 12\n",
      "Word 'works' has less than 30 sentences for sense 0: 0\n",
      "Word 'assume' has more than 5 senses: 7\n",
      "Word 'said' has less than 30 sentences for sense 0: 0\n",
      "Word 'man' has less than 30 sentences for sense 7: 17\n",
      "Word 'man' has more than 5 senses: 8\n",
      "Word 'flesh' has less than 30 sentences for sense 1: 1\n",
      "Word 'flesh' has less than 30 sentences for sense 3: 5\n",
      "Word 'flesh' has less than 30 sentences for sense 9: 23\n",
      "Word 'flesh' has more than 5 senses: 10\n",
      "Word 'approval' has less than 30 sentences for sense 2: 3\n",
      "Word 'feet' has less than 30 sentences for sense 0: 0\n",
      "Word 'lady' has less than 30 sentences for sense 3: 13\n",
      "Word 'down' has less than 30 sentences for sense 1: 16\n",
      "Word 'down' has less than 30 sentences for sense 3: 14\n",
      "Word 'down' has more than 5 senses: 8\n",
      "Word 'middle' has less than 30 sentences for sense 4: 18\n",
      "Word 'middle' has more than 5 senses: 6\n",
      "Word 'knowing' has less than 30 sentences for sense 0: 0\n",
      "Word 'beginning' has less than 30 sentences for sense 5: 17\n",
      "Word 'beginning' has more than 5 senses: 10\n",
      "Word 'knife' has less than 30 sentences for sense 1: 14\n",
      "Word 'role' has less than 30 sentences for sense 5: 3\n",
      "Word 'role' has less than 30 sentences for sense 7: 20\n",
      "Word 'role' has more than 5 senses: 8\n",
      "Word 'led' has less than 30 sentences for sense 0: 0\n",
      "Word 'review' has less than 30 sentences for sense 5: 2\n",
      "Word 'review' has more than 5 senses: 7\n",
      "Word 'asked' has less than 30 sentences for sense 0: 1\n",
      "Word 'covered' has less than 30 sentences for sense 0: 0\n",
      "Word 'runs' has less than 30 sentences for sense 0: 0\n",
      "Word 'broke' has less than 30 sentences for sense 0: 0\n",
      "Word 'sleep' has less than 30 sentences for sense 2: 5\n",
      "Word 'sleep' has less than 30 sentences for sense 3: 20\n",
      "Word 'sleep' has less than 30 sentences for sense 4: 7\n",
      "Word 'following' has more than 5 senses: 8\n",
      "Word 'contract' has more than 5 senses: 13\n",
      "Word 'mark' has less than 30 sentences for sense 0: 29\n",
      "Word 'add' has less than 30 sentences for sense 1: 3\n",
      "Word 'add' has less than 30 sentences for sense 4: 8\n",
      "Word 'bottom' has less than 30 sentences for sense 1: 18\n",
      "Word 'bottom' has less than 30 sentences for sense 2: 11\n",
      "Word 'bottom' has less than 30 sentences for sense 8: 23\n",
      "Word 'bottom' has less than 30 sentences for sense 9: 2\n",
      "Word 'bottom' has less than 30 sentences for sense 12: 7\n",
      "Word 'bottom' has less than 30 sentences for sense 14: 2\n",
      "Word 'bottom' has less than 30 sentences for sense 16: 9\n",
      "Word 'bottom' has less than 30 sentences for sense 17: 14\n",
      "Word 'bottom' has more than 5 senses: 16\n",
      "Word 'friend' has less than 30 sentences for sense 3: 1\n",
      "Word 'friend' has more than 5 senses: 7\n",
      "Word 'let' has less than 30 sentences for sense 1: 5\n",
      "Word 'let' has less than 30 sentences for sense 5: 7\n",
      "Word 'let' has more than 5 senses: 6\n",
      "Word 'practice' has less than 30 sentences for sense 5: 21\n",
      "Word 'practice' has more than 5 senses: 6\n",
      "Word 'using' has less than 30 sentences for sense 0: 0\n",
      "Word 'determine' has more than 5 senses: 7\n",
      "Word 'basis' has less than 30 sentences for sense 4: 2\n",
      "Word 'basis' has more than 5 senses: 6\n",
      "Word 'second' has less than 30 sentences for sense 3: 2\n",
      "Word 'second' has less than 30 sentences for sense 6: 1\n",
      "Word 'second' has less than 30 sentences for sense 7: 27\n",
      "Word 'second' has more than 5 senses: 11\n",
      "Word 'resolution' has less than 30 sentences for sense 3: 13\n",
      "Word 'resolution' has more than 5 senses: 8\n",
      "Word 'sat' has less than 30 sentences for sense 0: 0\n",
      "Word 'place' has less than 30 sentences for sense 1: 28\n",
      "Word 'place' has less than 30 sentences for sense 2: 26\n",
      "Word 'place' has less than 30 sentences for sense 3: 28\n",
      "Word 'place' has less than 30 sentences for sense 9: 22\n",
      "Word 'place' has less than 30 sentences for sense 10: 28\n",
      "Word 'place' has less than 30 sentences for sense 15: 8\n",
      "Word 'place' has less than 30 sentences for sense 16: 21\n",
      "Word 'place' has less than 30 sentences for sense 20: 4\n",
      "Word 'place' has less than 30 sentences for sense 21: 3\n",
      "Word 'place' has more than 5 senses: 29\n",
      "Word 'agree' has less than 30 sentences for sense 1: 25\n",
      "Word 'agree' has less than 30 sentences for sense 2: 26\n",
      "Word 'pair' has less than 30 sentences for sense 2: 13\n",
      "Word 'pair' has less than 30 sentences for sense 4: 1\n",
      "Word 'pair' has less than 30 sentences for sense 8: 24\n",
      "Word 'pair' has more than 5 senses: 9\n",
      "25111\n"
     ]
    }
   ],
   "source": [
    "df = keep_df\n",
    "print(len(df))\n",
    "# # if for each word any sense has less than 30 sentences, print the word and sense\n",
    "# for word in df.word.unique():\n",
    "#     senses = df[df['word'] == word]['sense'].unique()\n",
    "#     # if sense 0 has less than 30 sentences, remove the word\n",
    "#     sense0_count = len(df[(df['word'] == word) & (df['sense'] == 0)])\n",
    "#     if sense0_count < 30:\n",
    "#         print(f\"Word '{word}' has less than 30 sentences for sense 0: {sense0_count}\")\n",
    "#         df = df[df['word'] != word]\n",
    "\n",
    "#     else:\n",
    "\n",
    "#         # if any of the senses have less than 30 sentences, print the word and sense and remove the sense\n",
    "#         for sense in senses:\n",
    "#             sense_count = len(df[(df['word'] == word) & (df['sense'] == sense)])\n",
    "#             if sense_count < 30:\n",
    "#                 print(f\"Word '{word}' has less than 30 sentences for sense {sense}: {sense_count}\")\n",
    "#                 df = df[(df['word'] != word) | df['sense'] != sense]\n",
    "\n",
    "#         # if any word has less than 2 senses, remove the word\n",
    "#         if len(senses) < 2:\n",
    "#             df = df[df['word'] != word]\n",
    "\n",
    "#         # for words that have more than 5 senses, remove all senses except for the first 5\n",
    "#         elif len(senses) > 5:\n",
    "#             senses_to_keep = [0] \n",
    "#             for sense in senses:\n",
    "#                 if sense != 0:\n",
    "#                     senses_to_keep.append(sense)\n",
    "#                 if len(senses_to_keep) == 5:\n",
    "#                     break\n",
    "#             print(f\"Word '{word}' has more than 5 senses: {len(senses)}\")\n",
    "#             df = df[(df['word'] != word) | (df['sense'].isin(senses_to_keep))]\n",
    "#             # Verify the senses after removal\n",
    "#             senses = df[df['word'] == word]['sense'].unique()\n",
    "# Keep track of rows to remove\n",
    "rows_to_remove = set()\n",
    "\n",
    "# if for each word any sense has less than 30 sentences, print the word and sense\n",
    "for word in df.word.unique():\n",
    "    senses = df[df['word'] == word]['sense'].unique()\n",
    "    \n",
    "    # if sense 0 has less than 30 sentences, mark the word for removal\n",
    "    sense0_count = len(df[(df['word'] == word) & (df['sense'] == 0)])\n",
    "    if sense0_count < 30:\n",
    "        print(f\"Word '{word}' has less than 30 sentences for sense 0: {sense0_count}\")\n",
    "        rows_to_remove.update(df[df['word'] == word].index)\n",
    "    else:\n",
    "        # if any of the senses have less than 30 sentences, print the word and sense and mark the sense for removal\n",
    "        for sense in senses:\n",
    "            sense_count = len(df[(df['word'] == word) & (df['sense'] == sense)])\n",
    "            if sense_count < 30:\n",
    "                print(f\"Word '{word}' has less than 30 sentences for sense {sense}: {sense_count}\")\n",
    "                rows_to_remove.update(df[(df['word'] == word) & (df['sense'] == sense)].index)\n",
    "        \n",
    "        # if any word has less than 2 senses, mark the word for removal\n",
    "        if len(senses) < 2:\n",
    "            rows_to_remove.update(df[df['word'] == word].index)\n",
    "        \n",
    "        # for words that have more than 5 senses, mark all senses except for the first 5 for removal\n",
    "        elif len(senses) > 5:\n",
    "            senses_to_keep = [0]\n",
    "            for sense in senses:\n",
    "                if sense != 0:\n",
    "                    senses_to_keep.append(sense)\n",
    "                if len(senses_to_keep) == 5:\n",
    "                    break\n",
    "            print(f\"Word '{word}' has more than 5 senses: {len(senses)}\")\n",
    "            rows_to_remove.update(df[(df['word'] == word) & ~(df['sense'].isin(senses_to_keep))].index)\n",
    "\n",
    "# Remove all marked rows from the DataFrame\n",
    "df = df.drop(rows_to_remove)\n",
    "\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sense\n",
      "0    6422\n",
      "2    5554\n",
      "1    4984\n",
      "3    4184\n",
      "4    3744\n",
      "5     154\n",
      "Name: count, dtype: int64\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "# get a distribution of the senses\n",
    "print(df['sense'].value_counts())\n",
    "df\n",
    "print(df['word'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'regard': Counter({2: 93, 3: 67, 0: 60, 1: 41, 4: 31}), 'thick': Counter({3: 82, 1: 73, 0: 73, 2: 60}), 'sweet': Counter({2: 108, 0: 65, 1: 42}), 'sun': Counter({2: 102, 1: 86, 0: 43}), 'coming': Counter(), 'sharp': Counter({2: 72, 4: 69, 3: 61, 0: 40}), 'forest': Counter({0: 91, 1: 78, 2: 41}), 'formed': Counter(), 'expected': Counter(), 'broken': Counter({1: 99, 0: 86, 4: 72, 2: 70, 3: 68}), 'understanding': Counter({0: 91, 1: 86, 3: 30}), 'paper': Counter({2: 102, 3: 100, 4: 89, 1: 88, 0: 61}), 'being': Counter({2: 117, 3: 93, 4: 89, 0: 73, 1: 52}), 'young': Counter({2: 104, 0: 96, 1: 64}), 'neighborhood': Counter({0: 104, 2: 67, 1: 43, 3: 34}), 'wage': Counter({2: 102, 3: 101, 1: 74, 0: 73}), 'united': Counter({4: 101, 0: 101, 3: 32}), 'central': Counter({3: 102, 4: 102, 0: 92, 1: 60, 2: 48}), 'train': Counter({2: 94, 3: 88, 1: 73, 0: 41}), 'move': Counter({1: 96, 2: 82, 0: 78, 4: 69, 3: 42}), 'suggest': Counter({3: 101, 4: 101, 1: 83, 0: 77, 2: 51}), 'single': Counter({1: 97, 0: 89, 2: 50}), 'reasonable': Counter({0: 88, 2: 87, 1: 36}), 'project': Counter({0: 99, 4: 98, 3: 96, 2: 93, 1: 35}), 'group': Counter({0: 97, 2: 76, 1: 48}), 'club': Counter({4: 110, 0: 88, 3: 45, 1: 43, 2: 38}), 'given': Counter(), 'horses': Counter(), 'open': Counter({4: 99, 3: 97, 0: 88, 1: 70, 2: 54}), 'added': Counter(), 'child': Counter({4: 111, 0: 92, 3: 88, 1: 62, 2: 55}), 'company': Counter({1: 110, 2: 98, 0: 90, 3: 61, 4: 42}), 'rule': Counter({1: 107, 3: 99, 0: 91, 2: 75, 4: 59}), 'present': Counter({3: 104, 1: 85, 0: 54, 4: 45}), 'fundamental': Counter({3: 101, 1: 92, 0: 60, 2: 48}), 'authority': Counter({0: 101, 3: 89, 2: 72, 4: 64, 1: 46}), 'mean': Counter({3: 109, 2: 103, 0: 82, 4: 53, 1: 45}), 'believe': Counter({0: 98, 2: 90, 1: 75}), 'concerning': Counter({0: 100, 4: 99, 1: 78, 2: 39}), 'developed': Counter(), 'discussion': Counter({0: 102, 1: 98, 2: 91, 3: 65}), 'miss': Counter(), 'instance': Counter({2: 103, 3: 103, 4: 101, 0: 99, 1: 78}), 'march': Counter({4: 93, 0: 91, 2: 44, 1: 41}), 'pain': Counter(), 'hundred': Counter({3: 87, 1: 65, 0: 60}), 'contact': Counter({0: 96, 1: 89, 4: 71, 2: 48, 3: 48}), 'prove': Counter({1: 100, 2: 99, 4: 83, 3: 71, 0: 37}), 'heat': Counter({3: 100, 2: 73, 1: 53, 0: 35}), 'independent': Counter({0: 90, 2: 44, 1: 35}), 'appropriate': Counter({2: 101, 0: 77, 3: 64, 1: 55}), 'wonderful': Counter({0: 91, 4: 85, 1: 81, 2: 74, 3: 62}), 'love': Counter({1: 85, 0: 82, 3: 69, 2: 59}), 'works': Counter(), 'faculty': Counter({0: 102, 1: 86, 2: 34}), 'assume': Counter({4: 100, 0: 97, 2: 84, 3: 75, 1: 32}), 'stream': Counter({2: 96, 4: 71, 0: 59, 3: 39, 1: 36}), 'said': Counter(), 'man': Counter({2: 100, 1: 93, 4: 90, 3: 88, 0: 31}), 'flesh': Counter({4: 97, 0: 87, 2: 54}), 'approval': Counter({3: 94, 0: 81}), 'feet': Counter(), 'responsibility': Counter({3: 99, 0: 99, 1: 98, 2: 96}), 'lady': Counter({0: 91, 1: 62, 2: 30}), 'down': Counter({4: 78, 0: 77, 2: 66}), 'middle': Counter({3: 97, 0: 78, 2: 70, 1: 43}), 'research': Counter({1: 101, 2: 90, 0: 86}), 'knowing': Counter(), 'little': Counter({2: 107, 0: 104, 3: 77, 1: 69, 4: 42}), 'signal': Counter({0: 101, 1: 76, 2: 49}), 'beginning': Counter({0: 100, 3: 91, 4: 79, 2: 68, 1: 61}), 'knife': Counter({0: 101, 2: 92}), 'role': Counter({2: 87, 4: 83, 0: 79, 3: 68, 1: 65}), 'led': Counter(), 'particular': Counter({2: 81, 4: 62, 3: 59, 0: 57, 1: 38}), 'review': Counter({3: 102, 1: 98, 0: 91, 4: 48, 2: 40}), 'allow': Counter({2: 98, 3: 94, 4: 94, 1: 77, 0: 64}), 'asked': Counter(), 'covered': Counter(), 'runs': Counter(), 'trial': Counter({2: 72, 1: 47, 0: 43}), 'broke': Counter(), 'sleep': Counter({0: 76, 1: 32}), 'following': Counter({0: 100, 2: 97, 3: 90, 4: 85, 1: 64}), 'contract': Counter({4: 103, 1: 93, 0: 79, 3: 51, 2: 42}), 'mark': Counter(), 'add': Counter({5: 101, 2: 72, 0: 34}), 'bottom': Counter({0: 89, 3: 58, 5: 53}), 'content': Counter({2: 100, 1: 98, 3: 98, 4: 98, 0: 84}), 'friend': Counter({2: 106, 1: 99, 0: 82, 4: 48}), 'let': Counter({4: 123, 2: 101, 3: 79, 0: 33}), 'practice': Counter({2: 102, 1: 99, 0: 99, 4: 93, 3: 55}), 'using': Counter(), 'determine': Counter({0: 97, 1: 90, 4: 90, 2: 89, 3: 89}), 'basis': Counter({2: 103, 0: 102, 1: 46, 3: 34}), 'second': Counter({2: 98, 4: 88, 0: 87, 1: 48}), 'resolution': Counter({1: 103, 2: 103, 4: 97, 0: 96}), 'sat': Counter(), 'place': Counter({0: 78, 4: 63}), 'agree': Counter({0: 69}), 'produce': Counter({2: 100, 0: 84, 1: 82, 4: 76, 3: 56}), 'pair': Counter({1: 101, 0: 52, 3: 32})}\n",
      "Removed 8 sentences for word 'sweet' and sense 2\n",
      "Removed 2 sentences for word 'sun' and sense 2\n",
      "Removed 2 sentences for word 'paper' and sense 2\n",
      "Removed 17 sentences for word 'being' and sense 2\n",
      "Removed 4 sentences for word 'young' and sense 2\n",
      "Removed 4 sentences for word 'neighborhood' and sense 0\n",
      "Removed 2 sentences for word 'wage' and sense 2\n",
      "Removed 1 sentences for word 'wage' and sense 3\n",
      "Removed 1 sentences for word 'united' and sense 4\n",
      "Removed 1 sentences for word 'united' and sense 0\n",
      "Removed 2 sentences for word 'central' and sense 3\n",
      "Removed 2 sentences for word 'central' and sense 4\n",
      "Removed 1 sentences for word 'suggest' and sense 3\n",
      "Removed 1 sentences for word 'suggest' and sense 4\n",
      "Removed 10 sentences for word 'club' and sense 4\n",
      "Removed 11 sentences for word 'child' and sense 4\n",
      "Removed 10 sentences for word 'company' and sense 1\n",
      "Removed 7 sentences for word 'rule' and sense 1\n",
      "Removed 4 sentences for word 'present' and sense 3\n",
      "Removed 1 sentences for word 'fundamental' and sense 3\n",
      "Removed 1 sentences for word 'authority' and sense 0\n",
      "Removed 3 sentences for word 'mean' and sense 2\n",
      "Removed 9 sentences for word 'mean' and sense 3\n",
      "Removed 2 sentences for word 'discussion' and sense 0\n",
      "Removed 3 sentences for word 'instance' and sense 2\n",
      "Removed 3 sentences for word 'instance' and sense 3\n",
      "Removed 1 sentences for word 'instance' and sense 4\n",
      "Removed 1 sentences for word 'appropriate' and sense 2\n",
      "Removed 2 sentences for word 'faculty' and sense 0\n",
      "Removed 1 sentences for word 'research' and sense 1\n",
      "Removed 7 sentences for word 'little' and sense 2\n",
      "Removed 4 sentences for word 'little' and sense 0\n",
      "Removed 1 sentences for word 'signal' and sense 0\n",
      "Removed 1 sentences for word 'knife' and sense 0\n",
      "Removed 2 sentences for word 'review' and sense 3\n",
      "Removed 3 sentences for word 'contract' and sense 4\n",
      "Removed 1 sentences for word 'add' and sense 5\n",
      "Removed 6 sentences for word 'friend' and sense 2\n",
      "Removed 1 sentences for word 'let' and sense 2\n",
      "Removed 23 sentences for word 'let' and sense 4\n",
      "Removed 2 sentences for word 'practice' and sense 2\n",
      "Removed 3 sentences for word 'basis' and sense 2\n",
      "Removed 2 sentences for word 'basis' and sense 0\n",
      "Removed 3 sentences for word 'resolution' and sense 1\n",
      "Removed 3 sentences for word 'resolution' and sense 2\n",
      "Removed 1 sentences for word 'pair' and sense 1\n",
      "{'regard': Counter({2: 93, 3: 67, 0: 60, 1: 41, 4: 31}), 'thick': Counter({3: 82, 1: 73, 0: 73, 2: 60}), 'sweet': Counter({2: 100, 0: 65, 1: 42}), 'sun': Counter({2: 100, 1: 86, 0: 43}), 'coming': Counter(), 'sharp': Counter({2: 72, 4: 69, 3: 61, 0: 40}), 'forest': Counter({0: 91, 1: 78, 2: 41}), 'formed': Counter(), 'expected': Counter(), 'broken': Counter({1: 99, 0: 86, 4: 72, 2: 70, 3: 68}), 'understanding': Counter({0: 91, 1: 86, 3: 30}), 'paper': Counter({2: 100, 3: 100, 4: 89, 1: 88, 0: 61}), 'being': Counter({2: 100, 3: 93, 4: 89, 0: 73, 1: 52}), 'young': Counter({2: 100, 0: 96, 1: 64}), 'neighborhood': Counter({0: 100, 2: 67, 1: 43, 3: 34}), 'wage': Counter({2: 100, 3: 100, 1: 74, 0: 73}), 'united': Counter({4: 100, 0: 100, 3: 32}), 'central': Counter({3: 100, 4: 100, 0: 92, 1: 60, 2: 48}), 'train': Counter({2: 94, 3: 88, 1: 73, 0: 41}), 'move': Counter({1: 96, 2: 82, 0: 78, 4: 69, 3: 42}), 'suggest': Counter({3: 100, 4: 100, 1: 83, 0: 77, 2: 51}), 'single': Counter({1: 97, 0: 89, 2: 50}), 'reasonable': Counter({0: 88, 2: 87, 1: 36}), 'project': Counter({0: 99, 4: 98, 3: 96, 2: 93, 1: 35}), 'group': Counter({0: 97, 2: 76, 1: 48}), 'club': Counter({4: 100, 0: 88, 3: 45, 1: 43, 2: 38}), 'given': Counter(), 'horses': Counter(), 'open': Counter({4: 99, 3: 97, 0: 88, 1: 70, 2: 54}), 'added': Counter(), 'child': Counter({4: 100, 0: 92, 3: 88, 1: 62, 2: 55}), 'company': Counter({1: 100, 2: 98, 0: 90, 3: 61, 4: 42}), 'rule': Counter({1: 100, 3: 99, 0: 91, 2: 75, 4: 59}), 'present': Counter({3: 100, 1: 85, 0: 54, 4: 45}), 'fundamental': Counter({3: 100, 1: 92, 0: 60, 2: 48}), 'authority': Counter({0: 100, 3: 89, 2: 72, 4: 64, 1: 46}), 'mean': Counter({2: 100, 3: 100, 0: 82, 4: 53, 1: 45}), 'believe': Counter({0: 98, 2: 90, 1: 75}), 'concerning': Counter({0: 100, 4: 99, 1: 78, 2: 39}), 'developed': Counter(), 'discussion': Counter({0: 100, 1: 98, 2: 91, 3: 65}), 'miss': Counter(), 'instance': Counter({2: 100, 3: 100, 4: 100, 0: 99, 1: 78}), 'march': Counter({4: 93, 0: 91, 2: 44, 1: 41}), 'pain': Counter(), 'hundred': Counter({3: 87, 1: 65, 0: 60}), 'contact': Counter({0: 96, 1: 89, 4: 71, 2: 48, 3: 48}), 'prove': Counter({1: 100, 2: 99, 4: 83, 3: 71, 0: 37}), 'heat': Counter({3: 100, 2: 73, 1: 53, 0: 35}), 'independent': Counter({0: 90, 2: 44, 1: 35}), 'appropriate': Counter({2: 100, 0: 77, 3: 64, 1: 55}), 'wonderful': Counter({0: 91, 4: 85, 1: 81, 2: 74, 3: 62}), 'love': Counter({1: 85, 0: 82, 3: 69, 2: 59}), 'works': Counter(), 'faculty': Counter({0: 100, 1: 86, 2: 34}), 'assume': Counter({4: 100, 0: 97, 2: 84, 3: 75, 1: 32}), 'stream': Counter({2: 96, 4: 71, 0: 59, 3: 39, 1: 36}), 'said': Counter(), 'man': Counter({2: 100, 1: 93, 4: 90, 3: 88, 0: 31}), 'flesh': Counter({4: 97, 0: 87, 2: 54}), 'approval': Counter({3: 94, 0: 81}), 'feet': Counter(), 'responsibility': Counter({3: 99, 0: 99, 1: 98, 2: 96}), 'lady': Counter({0: 91, 1: 62, 2: 30}), 'down': Counter({4: 78, 0: 77, 2: 66}), 'middle': Counter({3: 97, 0: 78, 2: 70, 1: 43}), 'research': Counter({1: 100, 2: 90, 0: 86}), 'knowing': Counter(), 'little': Counter({2: 100, 0: 100, 3: 77, 1: 69, 4: 42}), 'signal': Counter({0: 100, 1: 76, 2: 49}), 'beginning': Counter({0: 100, 3: 91, 4: 79, 2: 68, 1: 61}), 'knife': Counter({0: 100, 2: 92}), 'role': Counter({2: 87, 4: 83, 0: 79, 3: 68, 1: 65}), 'led': Counter(), 'particular': Counter({2: 81, 4: 62, 3: 59, 0: 57, 1: 38}), 'review': Counter({3: 100, 1: 98, 0: 91, 4: 48, 2: 40}), 'allow': Counter({2: 98, 3: 94, 4: 94, 1: 77, 0: 64}), 'asked': Counter(), 'covered': Counter(), 'runs': Counter(), 'trial': Counter({2: 72, 1: 47, 0: 43}), 'broke': Counter(), 'sleep': Counter({0: 76, 1: 32}), 'following': Counter({0: 100, 2: 97, 3: 90, 4: 85, 1: 64}), 'contract': Counter({4: 100, 1: 93, 0: 79, 3: 51, 2: 42}), 'mark': Counter(), 'add': Counter({5: 100, 2: 72, 0: 34}), 'bottom': Counter({0: 89, 3: 58, 5: 53}), 'content': Counter({2: 100, 1: 98, 3: 98, 4: 98, 0: 84}), 'friend': Counter({2: 100, 1: 99, 0: 82, 4: 48}), 'let': Counter({2: 100, 4: 100, 3: 79, 0: 33}), 'practice': Counter({2: 100, 1: 99, 0: 99, 4: 93, 3: 55}), 'using': Counter(), 'determine': Counter({0: 97, 1: 90, 4: 90, 2: 89, 3: 89}), 'basis': Counter({2: 100, 0: 100, 1: 46, 3: 34}), 'second': Counter({2: 98, 4: 88, 0: 87, 1: 48}), 'resolution': Counter({1: 100, 2: 100, 4: 97, 0: 96}), 'sat': Counter(), 'place': Counter({0: 78, 4: 63}), 'agree': Counter({0: 69}), 'produce': Counter({2: 100, 0: 84, 1: 82, 4: 76, 3: 56}), 'pair': Counter({1: 100, 0: 52, 3: 32})}\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# for each word, show how many sentences there are for each sense\n",
    "word_sense_counts = {word: Counter(df[df['word'] == word]['sense']) for word in word_synonym_sentences.keys()}\n",
    "print(word_sense_counts)\n",
    "\n",
    "rows_to_remove = set()\n",
    "# for each word, for each sense keep only 100 sentences\n",
    "for word in df.word.unique():\n",
    "    senses = df[df['word'] == word]['sense'].unique()\n",
    "    for sense in senses:\n",
    "        sense_count = len(df[(df['word'] == word) & (df['sense'] == sense)])\n",
    "        if sense_count > 100:\n",
    "            rows_to_remove.update(df[(df['word'] == word) & (df['sense'] == sense)].index[100:])\n",
    "            print(f\"Removed {sense_count - 100} sentences for word '{word}' and sense {sense}\")\n",
    "\n",
    "# Remove all marked rows from the DataFrame\n",
    "df = df.drop(rows_to_remove)\n",
    "# check how many sentences there are for each sense\n",
    "word_sense_counts = {word: Counter(df[df['word'] == word]['sense']) for word in word_synonym_sentences.keys()}\n",
    "print(word_sense_counts)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if any words don't have sense 0 or have less than 30 sentences for sense 0\n",
    "for word in df['word'].unique():\n",
    "    sense0_count = len(df[(df['word'] == word) & (df['sense'] == 0)])\n",
    "    if sense0_count < 30:\n",
    "        print(f\"Word '{word}' has less than 30 sentences for sense 0: {sense0_count}\")\n",
    "\n",
    "    # remove those words from the df\n",
    "    # df = df.drop(df[(df['word'] == word) & (df['sense'] == 0)].index)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 'agree' has less than 2 senses\n"
     ]
    }
   ],
   "source": [
    "# for each word check what senses have less than 30 sentences and remove them\n",
    "rows_to_remove = set()\n",
    "for word in df['word'].unique():\n",
    "    senses = df[df['word'] == word]['sense'].unique()\n",
    "    for sense in senses:\n",
    "        sense_count = len(df[(df['word'] == word) & (df['sense'] == sense)])\n",
    "        if sense_count < 30:\n",
    "            print(f\"Word '{word}' has less than 30 sentences for sense {sense}: {sense_count}\")\n",
    "            rows_to_remove.update(df[(df['word'] == word) & (df['sense'] == sense)].index)\n",
    "            \n",
    "df = df.drop(rows_to_remove)\n",
    "\n",
    "# if the word has less than 2 senses, remove it\n",
    "rows_to_remove = set()\n",
    "for word in df['word'].unique():\n",
    "    senses = df[df['word'] == word]['sense'].unique()\n",
    "    if len(senses) < 2:\n",
    "        print(f\"Word '{word}' has less than 2 senses\")\n",
    "        rows_to_remove.update(df[df['word'] == word].index)\n",
    "\n",
    "df = df.drop(rows_to_remove)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    }
   ],
   "source": [
    "# check how many words remain in df\n",
    "print(len(df['word'].unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word\n",
       "content        478\n",
       "instance       477\n",
       "determine      455\n",
       "practice       446\n",
       "paper          438\n",
       "              ... \n",
       "approval       175\n",
       "independent    169\n",
       "trial          162\n",
       "place          141\n",
       "sleep          108\n",
       "Name: count, Length: 80, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['word'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the \\n from the end of the sentences\n",
    "df['sentence'] = df['sentence'].str.replace('\\n', '')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regard: sense\n",
      "2    93\n",
      "3    67\n",
      "0    60\n",
      "1    41\n",
      "4    31\n",
      "Name: count, dtype: int64\n",
      "thick: sense\n",
      "3    82\n",
      "1    73\n",
      "0    73\n",
      "2    60\n",
      "Name: count, dtype: int64\n",
      "sweet: sense\n",
      "2    100\n",
      "0     65\n",
      "1     42\n",
      "Name: count, dtype: int64\n",
      "sun: sense\n",
      "2    100\n",
      "1     86\n",
      "0     43\n",
      "Name: count, dtype: int64\n",
      "sharp: sense\n",
      "2    72\n",
      "4    69\n",
      "3    61\n",
      "0    40\n",
      "Name: count, dtype: int64\n",
      "forest: sense\n",
      "0    91\n",
      "1    78\n",
      "2    41\n",
      "Name: count, dtype: int64\n",
      "broken: sense\n",
      "1    99\n",
      "0    86\n",
      "4    72\n",
      "2    70\n",
      "3    68\n",
      "Name: count, dtype: int64\n",
      "understanding: sense\n",
      "0    91\n",
      "1    86\n",
      "3    30\n",
      "Name: count, dtype: int64\n",
      "paper: sense\n",
      "2    100\n",
      "3    100\n",
      "4     89\n",
      "1     88\n",
      "0     61\n",
      "Name: count, dtype: int64\n",
      "being: sense\n",
      "2    100\n",
      "3     93\n",
      "4     89\n",
      "0     73\n",
      "1     52\n",
      "Name: count, dtype: int64\n",
      "young: sense\n",
      "2    100\n",
      "0     96\n",
      "1     64\n",
      "Name: count, dtype: int64\n",
      "neighborhood: sense\n",
      "0    100\n",
      "2     67\n",
      "1     43\n",
      "3     34\n",
      "Name: count, dtype: int64\n",
      "wage: sense\n",
      "2    100\n",
      "3    100\n",
      "1     74\n",
      "0     73\n",
      "Name: count, dtype: int64\n",
      "united: sense\n",
      "4    100\n",
      "0    100\n",
      "3     32\n",
      "Name: count, dtype: int64\n",
      "central: sense\n",
      "3    100\n",
      "4    100\n",
      "0     92\n",
      "1     60\n",
      "2     48\n",
      "Name: count, dtype: int64\n",
      "train: sense\n",
      "2    94\n",
      "3    88\n",
      "1    73\n",
      "0    41\n",
      "Name: count, dtype: int64\n",
      "move: sense\n",
      "1    96\n",
      "2    82\n",
      "0    78\n",
      "4    69\n",
      "3    42\n",
      "Name: count, dtype: int64\n",
      "suggest: sense\n",
      "3    100\n",
      "4    100\n",
      "1     83\n",
      "0     77\n",
      "2     51\n",
      "Name: count, dtype: int64\n",
      "single: sense\n",
      "1    97\n",
      "0    89\n",
      "2    50\n",
      "Name: count, dtype: int64\n",
      "reasonable: sense\n",
      "0    88\n",
      "2    87\n",
      "1    36\n",
      "Name: count, dtype: int64\n",
      "project: sense\n",
      "0    99\n",
      "4    98\n",
      "3    96\n",
      "2    93\n",
      "1    35\n",
      "Name: count, dtype: int64\n",
      "group: sense\n",
      "0    97\n",
      "2    76\n",
      "1    48\n",
      "Name: count, dtype: int64\n",
      "club: sense\n",
      "4    100\n",
      "0     88\n",
      "3     45\n",
      "1     43\n",
      "2     38\n",
      "Name: count, dtype: int64\n",
      "open: sense\n",
      "4    99\n",
      "3    97\n",
      "0    88\n",
      "1    70\n",
      "2    54\n",
      "Name: count, dtype: int64\n",
      "child: sense\n",
      "4    100\n",
      "0     92\n",
      "3     88\n",
      "1     62\n",
      "2     55\n",
      "Name: count, dtype: int64\n",
      "company: sense\n",
      "1    100\n",
      "2     98\n",
      "0     90\n",
      "3     61\n",
      "4     42\n",
      "Name: count, dtype: int64\n",
      "rule: sense\n",
      "1    100\n",
      "3     99\n",
      "0     91\n",
      "2     75\n",
      "4     59\n",
      "Name: count, dtype: int64\n",
      "present: sense\n",
      "3    100\n",
      "1     85\n",
      "0     54\n",
      "4     45\n",
      "Name: count, dtype: int64\n",
      "fundamental: sense\n",
      "3    100\n",
      "1     92\n",
      "0     60\n",
      "2     48\n",
      "Name: count, dtype: int64\n",
      "authority: sense\n",
      "0    100\n",
      "3     89\n",
      "2     72\n",
      "4     64\n",
      "1     46\n",
      "Name: count, dtype: int64\n",
      "mean: sense\n",
      "2    100\n",
      "3    100\n",
      "0     82\n",
      "4     53\n",
      "1     45\n",
      "Name: count, dtype: int64\n",
      "believe: sense\n",
      "0    98\n",
      "2    90\n",
      "1    75\n",
      "Name: count, dtype: int64\n",
      "concerning: sense\n",
      "0    100\n",
      "4     99\n",
      "1     78\n",
      "2     39\n",
      "Name: count, dtype: int64\n",
      "discussion: sense\n",
      "0    100\n",
      "1     98\n",
      "2     91\n",
      "3     65\n",
      "Name: count, dtype: int64\n",
      "instance: sense\n",
      "2    100\n",
      "3    100\n",
      "4    100\n",
      "0     99\n",
      "1     78\n",
      "Name: count, dtype: int64\n",
      "march: sense\n",
      "4    93\n",
      "0    91\n",
      "2    44\n",
      "1    41\n",
      "Name: count, dtype: int64\n",
      "hundred: sense\n",
      "3    87\n",
      "1    65\n",
      "0    60\n",
      "Name: count, dtype: int64\n",
      "contact: sense\n",
      "0    96\n",
      "1    89\n",
      "4    71\n",
      "2    48\n",
      "3    48\n",
      "Name: count, dtype: int64\n",
      "prove: sense\n",
      "1    100\n",
      "2     99\n",
      "4     83\n",
      "3     71\n",
      "0     37\n",
      "Name: count, dtype: int64\n",
      "heat: sense\n",
      "3    100\n",
      "2     73\n",
      "1     53\n",
      "0     35\n",
      "Name: count, dtype: int64\n",
      "independent: sense\n",
      "0    90\n",
      "2    44\n",
      "1    35\n",
      "Name: count, dtype: int64\n",
      "appropriate: sense\n",
      "2    100\n",
      "0     77\n",
      "3     64\n",
      "1     55\n",
      "Name: count, dtype: int64\n",
      "wonderful: sense\n",
      "0    91\n",
      "4    85\n",
      "1    81\n",
      "2    74\n",
      "3    62\n",
      "Name: count, dtype: int64\n",
      "love: sense\n",
      "1    85\n",
      "0    82\n",
      "3    69\n",
      "2    59\n",
      "Name: count, dtype: int64\n",
      "faculty: sense\n",
      "0    100\n",
      "1     86\n",
      "2     34\n",
      "Name: count, dtype: int64\n",
      "assume: sense\n",
      "4    100\n",
      "0     97\n",
      "2     84\n",
      "3     75\n",
      "1     32\n",
      "Name: count, dtype: int64\n",
      "stream: sense\n",
      "2    96\n",
      "4    71\n",
      "0    59\n",
      "3    39\n",
      "1    36\n",
      "Name: count, dtype: int64\n",
      "man: sense\n",
      "2    100\n",
      "1     93\n",
      "4     90\n",
      "3     88\n",
      "0     31\n",
      "Name: count, dtype: int64\n",
      "flesh: sense\n",
      "4    97\n",
      "0    87\n",
      "2    54\n",
      "Name: count, dtype: int64\n",
      "approval: sense\n",
      "3    94\n",
      "0    81\n",
      "Name: count, dtype: int64\n",
      "responsibility: sense\n",
      "3    99\n",
      "0    99\n",
      "1    98\n",
      "2    96\n",
      "Name: count, dtype: int64\n",
      "lady: sense\n",
      "0    91\n",
      "1    62\n",
      "2    30\n",
      "Name: count, dtype: int64\n",
      "down: sense\n",
      "4    78\n",
      "0    77\n",
      "2    66\n",
      "Name: count, dtype: int64\n",
      "middle: sense\n",
      "3    97\n",
      "0    78\n",
      "2    70\n",
      "1    43\n",
      "Name: count, dtype: int64\n",
      "research: sense\n",
      "1    100\n",
      "2     90\n",
      "0     86\n",
      "Name: count, dtype: int64\n",
      "little: sense\n",
      "2    100\n",
      "0    100\n",
      "3     77\n",
      "1     69\n",
      "4     42\n",
      "Name: count, dtype: int64\n",
      "signal: sense\n",
      "0    100\n",
      "1     76\n",
      "2     49\n",
      "Name: count, dtype: int64\n",
      "beginning: sense\n",
      "0    100\n",
      "3     91\n",
      "4     79\n",
      "2     68\n",
      "1     61\n",
      "Name: count, dtype: int64\n",
      "knife: sense\n",
      "0    100\n",
      "2     92\n",
      "Name: count, dtype: int64\n",
      "role: sense\n",
      "2    87\n",
      "4    83\n",
      "0    79\n",
      "3    68\n",
      "1    65\n",
      "Name: count, dtype: int64\n",
      "particular: sense\n",
      "2    81\n",
      "4    62\n",
      "3    59\n",
      "0    57\n",
      "1    38\n",
      "Name: count, dtype: int64\n",
      "review: sense\n",
      "3    100\n",
      "1     98\n",
      "0     91\n",
      "4     48\n",
      "2     40\n",
      "Name: count, dtype: int64\n",
      "allow: sense\n",
      "2    98\n",
      "3    94\n",
      "4    94\n",
      "1    77\n",
      "0    64\n",
      "Name: count, dtype: int64\n",
      "trial: sense\n",
      "2    72\n",
      "1    47\n",
      "0    43\n",
      "Name: count, dtype: int64\n",
      "sleep: sense\n",
      "0    76\n",
      "1    32\n",
      "Name: count, dtype: int64\n",
      "following: sense\n",
      "0    100\n",
      "2     97\n",
      "3     90\n",
      "4     85\n",
      "1     64\n",
      "Name: count, dtype: int64\n",
      "contract: sense\n",
      "4    100\n",
      "1     93\n",
      "0     79\n",
      "3     51\n",
      "2     42\n",
      "Name: count, dtype: int64\n",
      "add: sense\n",
      "5    100\n",
      "2     72\n",
      "0     34\n",
      "Name: count, dtype: int64\n",
      "bottom: sense\n",
      "0    89\n",
      "3    58\n",
      "5    53\n",
      "Name: count, dtype: int64\n",
      "content: sense\n",
      "2    100\n",
      "1     98\n",
      "3     98\n",
      "4     98\n",
      "0     84\n",
      "Name: count, dtype: int64\n",
      "friend: sense\n",
      "2    100\n",
      "1     99\n",
      "0     82\n",
      "4     48\n",
      "Name: count, dtype: int64\n",
      "let: sense\n",
      "2    100\n",
      "4    100\n",
      "3     79\n",
      "0     33\n",
      "Name: count, dtype: int64\n",
      "practice: sense\n",
      "2    100\n",
      "1     99\n",
      "0     99\n",
      "4     93\n",
      "3     55\n",
      "Name: count, dtype: int64\n",
      "determine: sense\n",
      "0    97\n",
      "1    90\n",
      "4    90\n",
      "2    89\n",
      "3    89\n",
      "Name: count, dtype: int64\n",
      "basis: sense\n",
      "2    100\n",
      "0    100\n",
      "1     46\n",
      "3     34\n",
      "Name: count, dtype: int64\n",
      "second: sense\n",
      "2    98\n",
      "4    88\n",
      "0    87\n",
      "1    48\n",
      "Name: count, dtype: int64\n",
      "resolution: sense\n",
      "1    100\n",
      "2    100\n",
      "4     97\n",
      "0     96\n",
      "Name: count, dtype: int64\n",
      "place: sense\n",
      "0    78\n",
      "4    63\n",
      "Name: count, dtype: int64\n",
      "produce: sense\n",
      "2    100\n",
      "0     84\n",
      "1     82\n",
      "4     76\n",
      "3     56\n",
      "Name: count, dtype: int64\n",
      "pair: sense\n",
      "1    100\n",
      "0     52\n",
      "3     32\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for word in df['word'].unique():\n",
    "    # print the sense value counts for each word\n",
    "    print(f\"{word}: {df[df['word'] == word]['sense'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('English_pseudo_polysemy_wsd_corpus_2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24862\n",
      "4800\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('English_pseudo_polysemy_wsd_corpus_2.csv')\n",
    "print(len(df))\n",
    "\n",
    "# for each word keep only 30 sentences from 2 senses (sense 0 and the next sense) and remove the rest\n",
    "rows_to_remove = set()\n",
    "for word in df['word'].unique():\n",
    "    senses = df[df['word'] == word]['sense'].unique()\n",
    "    if len(senses) > 2:\n",
    "        for sense in senses[2:]:\n",
    "            rows_to_remove.update(df[(df['word'] == word) & (df['sense'] == sense)].index)\n",
    "    for sense in senses[:2]:\n",
    "        rows_to_remove.update(df[(df['word'] == word) & (df['sense'] == sense)][30:].index)\n",
    "df = df.drop(rows_to_remove)\n",
    "\n",
    "print(len(df), df['word'].nunique() * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regard\n",
      "thick\n",
      "sweet\n",
      "sun\n",
      "sharp\n",
      "forest\n",
      "broken\n",
      "understanding\n",
      "paper\n",
      "being\n",
      "young\n",
      "neighborhood\n",
      "wage\n",
      "united\n",
      "central\n",
      "train\n",
      "move\n",
      "suggest\n",
      "single\n",
      "reasonable\n",
      "project\n",
      "group\n",
      "club\n",
      "open\n",
      "child\n",
      "company\n",
      "rule\n",
      "present\n",
      "fundamental\n",
      "authority\n",
      "mean\n",
      "believe\n",
      "concerning\n",
      "discussion\n",
      "instance\n",
      "march\n",
      "hundred\n",
      "contact\n",
      "prove\n",
      "heat\n",
      "independent\n",
      "appropriate\n",
      "wonderful\n",
      "love\n",
      "faculty\n",
      "assume\n",
      "stream\n",
      "man\n",
      "flesh\n",
      "approval\n",
      "responsibility\n",
      "lady\n",
      "down\n",
      "middle\n",
      "research\n",
      "little\n",
      "signal\n",
      "beginning\n",
      "knife\n",
      "role\n",
      "particular\n",
      "review\n",
      "allow\n",
      "trial\n",
      "sleep\n",
      "following\n",
      "contract\n",
      "add\n",
      "bottom\n",
      "content\n",
      "friend\n",
      "let\n",
      "practice\n",
      "determine\n",
      "basis\n",
      "second\n",
      "resolution\n",
      "place\n",
      "produce\n",
      "pair\n"
     ]
    }
   ],
   "source": [
    "# print each word and their sense value counts\n",
    "for word in df['word'].unique():\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('English_pseudo_polysemy_30_sents_each.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
